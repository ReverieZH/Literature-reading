当一幅图像具有相似的前景和背景颜色或复杂的纹理时，以往的算法的性能较差。主要原因是之前的方法

​	1)只使用低层次的特征

​	2)缺乏高层次的上下文特征

在本文中，我们提出了一种新的基于深度学习的算法来解决这两个问题。

我们的深度模型有两部分

1. 第一部分是深度卷积编解码器网络，以图像和相应的三位映射作为输入，预测图像的alpha matte

   2.第二部分是一个小的卷积网络用来改进第一个网络的alpha matte预测，以获得更精确的alpha值和更清晰的边缘

# 一、引言



不幸的是，目前的抠图方法并不能很好地适用于典型的日常场景。这部分是由于问题的困难：如上所述，匹配问题的约束不足，每像素有7个未知值，但只有3个已知值：像素i处的RGB颜色，$I_i$已知，前景色$F_i$、背景色$B_i$和alpha估计αi未知。然而，目前的方法也受到了进一步的限制。

第一个限制是由于目前设计的方法来求解matting方程.这个方程将matting问题定义为两种颜色的线性组合，因此目前大多数算法在很大程度上作为一个颜色问题。标准方法包括对前景和背景颜色[3,9]进行采样，根据matting方程[14,31,22]传播alpha值，或两个[32,13,28,16]的混合。这种方法在很大程度上依赖于颜色的区别特征（通常随着像素的空间位置），使他们对于前景和背景颜色分布重叠的情况下非常敏感，不幸的是，对于这些方法在自然图像下是常见情况，经常导致低频“涂抹”或高频“大块”工件（见图1顶部行）。甚至最近提出的深度学习方法也高度依赖于颜色的传播方法

第二个限制是由于关注于一个非常小的数据集



在这项工作中，我们提出了一种旨在克服这些限制的方法。**我们的方法使用深度学习直接计算给定输入图像的alpha matte。我们的网络不再主要依赖颜色信息，而是可以学习自然结构**。例如，头发和毛皮（通常需要垫子）具有很强的结构和纹理图案。在其他需要抠图的情况下（例如，物体的边缘，光学或运动模糊区域，或半透明区域）几乎总是有一个可以预期的共同结构或alpha。虽然低级别的特征不会捕获这种结构，但深度网络是表示它的理想结构。我们的两阶段网络包括一个编码器-解码器阶段，然后是一个小的残差网络进行改进，并包括一个新的组合损失和在alpha上的损失。我们是第一个演示能力学习一个alpha哑光端到端给定一个图像和三映射。

为了训练一个在无约束场景的自然图像中表现出色的模型，我们需要一个比目前可用的数据更大的数据集。使用[25]的方法获取真实数据集将是非常昂贵的，并且不能处理任何运动程度的场景（因此不能捕捉人类或动物）。相反，受到其他合成数据集的启发，这些数据集已被证明足以训练模型用于真实图像（例如，[4]），**我们使用组合创建了一个大规模的匹配数据集**。仔细提取对象在简单背景上的图像，并将其合成到新的背景图像上，以创建一个包含49300张训练图像和1000张测试图像的数据集。

我们进行了广泛的评估来证明我们的方法的有效性。我们的方法不仅在alphamatting.com挑战中获得了第一名，而且在我们的合成测试集上也大大优于之前的方法。我们展示了我们学习到的模型推广到自然图像，用户研究比较了许多不同的方法，31个在不同的场景下，包括人类、动物和其他物体的自然图像。这项研究显示了对我们的结果的强烈偏好，但也表明，在由人类判断时，一些在alphamatting.com数据集上表现良好的方法实际上比其他方法表现更差，这表明方法在alphamatting.com测试集上被过度拟合。最后，我们还表明，我们是更稳健的三聚体放置比其他方法。

最后，我们还表明，我们对trimap放置比其他方法更稳健。

事实上，即使在trimap中没有已知的前景和/或背景，我们也可以产生很好的结果，而大多数方法不能返回任何结果

# 二、相关工作

目前的matting方法主要依靠颜色、位置或其他低级特征来确定alpha matte，通过采样、传播或两者的结合来实现。

在基于采样的方法[3,9,32,13,28,16]中，对已知的前景和背景区域进行采样，以寻找给定像素的前景和背景的候选颜色，然后使用度量来确定最佳的前景/背景组合。采用了不同的采样方法，包括沿着最接近给定像素[32]的边界进行采样，基于射线投射[13]的采样，搜索整个边界[16]，或从颜色簇[28,12]中进行采样。在抽样候选之间决定的度量几乎总是包括一个matting方程重建误差，可能是samples与给定像素[32,16]的距离或前景和背景样本[32,28]的相似性，公式包括稀疏编码[12]和kl散度方法

在传播方法中，等式1被重新表述，这样它允许alpha值从已知的前景和背景区域传播到未知区域。一种流行的方法是Closed-form matting [22]，通常用于[32,16,28]采样后的后处理。它从前景和背景颜色的局部光滑假设导出一个代价函数，并通过求解稀疏线性方程组找到全局最优的alpha matte。其他的传播方法包括随机游动[14]、求解泊松方程[31]和非局部传播方法

最近，人们提出了一些关于 image matting的深度学习工作。然而，他们不直接学习 alpha matte从给定的图像和trimap。Shen等人[29]使用深度学习在肖像图像中创建一个人的trimap，并使用[22]进行匹配，通过[22]将matting错误反向传播到网络。Cho等人[8]将[22]和[5]的matting结果以及标准化的RGB颜色作为输入，并学习一个端到端深度网络来预测一个新的alpha matte。虽然我们的算法和两者都利用了深度学习，但我们的算法与他们的算法有很大的不同。

# 三、**New matting dataset**

为了训练我们的matting网络，我们通过将真实图像中的对象组合到新的背景上来创建一个更大的数据集。我们在简单或简单背景上找到图像(图2a)，包括[25]的27张训练图像，[26]的视频每五帧。使用PhotoShop，我们仔细地手动创建了一个alpha matte（图2b）和纯前景颜色(图2c）。因为这些物体有简单的背景，所以我们可以为它们画出精确的alpha matte。然后，我们将这些作为地面事实，对于每一个alpha matte和前景图像，我们在MSCOCO[23]和PascalVOC[11]中随机抽取N个背景图像，并将对象合成到这些背景图像上

我们用上述方法创建了一个训练数据集和一个测试数据集。我们的训练数据集有493个独特的前景对象和49,300张图像(N=100)，而我们的测试数据集有50个独特的对象和1000张图像(N=20)。每个图像的三幅图是随机扩张从它的地面真相阿尔法哑光。与以前的匹配数据集相比，我们的新数据集有几个优点。1)它有更多独特的物体，覆盖各种垫子案例，如头发，皮毛，半透明等。2)许多合成图像具有相似的前景和背景颜色，以及复杂的背景纹理，使我们的数据集更具挑战性和实用性。

早期的一个问题是，这一过程是否会由于图像的合成性质而产生偏差，这样一个网络就会在前景和背景照明、噪音水平等中学习关键化的差异。然而，我们通过实验发现，与之前的方法相比，我们在自然图像上取得了远远优越的结果

# 四、我们的方法

我们使用深度学习来解决image matting问题。给定我们的新数据集，我们训练一个神经网络来充分利用这些数据。该网络分为两个阶段（图3）。

第一阶段是深度卷积编码解码器网络，它以图像和trimap作为输入，并受到alpha预测损失和新的合成损失的惩罚

第二阶段是一个小型的全卷积网络，它从第一个网络中改进了具有更精确的alpha值和更清晰的边缘的alpha预测。我们将在下面的部分中更详细地描述我们的算法

![image-20220525153641270](C:\Users\13449\AppData\Roaming\Typora\typora-user-images\image-20220525153641270.png)

## 4.1**. Matting encoder-decoder stage**

**Network structure:** 

网络的输入是一个图像和相应的trimap，它们沿着通道尺寸连接，从而产生一个4通道的输入。整个网络由一个编码器网络和一个解码器网络组成。编码器网络的输入通过随后的卷积层和最大池化层转换为降采样的特征图。译码器网络反过来使用后续的非池化层，反向最大池化操作和卷积层来上采样特征映射，并有期望的输出，在我们的例子中是alpha matte。

具体来说，我们的编码器网络有14个卷积层和5个最大池化层。对于解码器网络，我们使用一个比编码器网络更小的结构来减少参数的数量和加快训练过程。具体来说，我们的解码器网络有6个卷积层，5个非池化层，然后是最后的alpha预测层。

**Losses:** 

我们的网络利用了两个损失。

第一个损失称为alpha 预测损失，它是每个像素的真实alpha 值和预测alpha 值之间的绝对差。但是，由于绝对值的不可微性质，我们使用下面的损失函数来近似它

![image-20220525155958669](C:\Users\13449\AppData\Roaming\Typora\typora-user-images\image-20220525155958669.png)

$a_i^p$是在像素i处的预测层的输出值(在0到1之间)，$a_i^g$是在像素i处的真实值， $\epsilon=10^{-6}$

![image-20220525160256934](C:\Users\13449\AppData\Roaming\Typora\typora-user-images\image-20220525160256934.png)

第二种损失称为合成损失，它是地面真实的RGB颜色和使用真实前景、真实背景和预测的 alpha mattes组成的预测的RGB颜色之间的绝对差异。类似地，我们用以下的损失函数来近似它

![image-20220525160342485](C:\Users\13449\AppData\Roaming\Typora\typora-user-images\image-20220525160342485.png)

c为RGB通道，p为预测的alpha合成的图像，g为地面真实阿尔法合成的图像。合成损失限制了网络遵循成分操作，从而导致更准确的阿尔法预测。

![image-20220525160747418](C:\Users\13449\AppData\Roaming\Typora\typora-user-images\image-20220525160747418.png)

$w_l$设置为0.5

此外，由于只需要推断trimaps未知区域内的alpha值，因此我们根据像素位置对这两种类型的损失设置额外的权重，这有助于我们的网络更多地关注重要的区域。具体来说，如果像素i在trimaps的未知区域内，则$w_i$=1，否则$w_i$=0。

**Implementation:** 

为了避免过拟合以及更有效地利用训练数据，我们使用了几种训练策略。

首先，我们随机裁剪320对320×320（图像，三聚体）。这就增加了我们的采样空间。

其次，我们还裁剪了不同大小的训练对（如480×480,640×640），并将它们调整为320×320。这使得我们的方法对扩展更加鲁棒性，并帮助网络更好地学习上下文和语义。

第三，对每个训练对随机进行翻转。

第四，trimaps从它们的地面真实alpha mattes中随机膨胀，帮助我们的模型对trimap的放置更稳健。

最后，在每个训练阶段之后随机重新创建训练输入。

网络的编码器部分用VGG-16[30]的前14个卷积层进行初始化(第14层是完全连接的层“fc6”，可以转换为卷积层)。由于网络有4通道的输入，我们用零初始化第一层卷积滤波器的一个额外通道。所有的解码器参数都用Xavier随机变量进行初始化

在测试时，图像和相应的trimap被连接起来作为输入。对网络进行前传来输出 alpha matte预测。当GPU内存不足以处理大图像时，可以执行CPU测试

##  **4.2 Matting refifinement stage**

虽然来自我们网络的第一部分的alpha预测已经比现有的匹配算法要好得多，但由于编码器-解码器的结构，结果有时过于平滑。因此，我们扩展了我们的网络，以进一步细化从第一部分开始的结果。这个扩展的网络通常可以预测出更准确的alpha matte和更清晰的边缘

**Network structure:** 

我们的网络的第二阶段的输入是一个图像和它从第一阶段的alpha预测（在0到255之间扩展）的连接，从而产生一个4通道的输入。

输出是相应的地面真实值。该网络是一个包含4个卷积层的全卷积网络。前3个卷积层后面都有一个非线性的“ReLU”层。没有降采样层，因为我们希望保持在第一阶段所遗漏的非常微妙的结构。此外，我们还使用了一个“skip-model”结构，其中，输入数据的第4个通道首先在0到1之间进行缩放，然后被添加到网络的输出中。具体配置如图3所示。

细化阶段的效果如图4所示。请注意，它不会对alpha matte进行大规模的更改，而只是细化和锐化alpha值

![image-20220525161642810](C:\Users\13449\AppData\Roaming\Typora\typora-user-images\image-20220525161642810.png)

**Implementation:** 

在训练过程中，我们首先更新编码解码器部分，而没有细化部分。在编解码器部分收敛后，我们修正其参数，然后更新细化部分。

只有alpha预测损失(Eq 2)由于其结构简单而被使用。

除了第四个策略之外，我们也使用了第一阶段的所有训练策略。在细化部分也收敛后，我们一起对整个网络进行微调。我们使用Adam[20]来更新这两个部分。在训练过程中不断设置一个小的学习率$10^{−5}$。

在测试过程中，给定一个图像和一个 trimap，我们的算法首先使用匹配编码-解码器阶段得到一个初始的alpha matte预测。然后将图像和alpha预测连接起来，作为细化阶段的输入，以生成最终的alpha哑光预测。