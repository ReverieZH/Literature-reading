

# Local Convolutional Features with Unsupervised Training for Image Retrieval

基于CNN特征的分类方法——局部表示聚合——实现了一些特定的检测算法来提取输入图像中感兴趣的区域。

网络(Patch-CKN)[33]利用黑森仿射检测器提取输入图像中感兴趣的区域

# 摘要

补丁级描述符是一些重要的计算机视觉任务的基础，如立体匹配或基于轮廓的图像检索。我们引入了一个深度卷积架构，可以产生补丁级描述符，作为流行的SIFT描述符的替代方法。

被提出的描述符族，称为PatchCKN，采用了最近引入的卷积核网络(CKN)，这是一个学习卷积架构的无监督框架。

我们提出了一个比较框架，用来基准测试比较当前的深度卷积方法和Patch-CKN用于Patch和图像检索，包括我们的新“*RomePatches*”数据集。与监督CNN相比，Patch-CKN描述符在补丁和图像检索方面产生了有竞争力的结果。



# 1.引言



本文介绍了一种不需要监督的基于深度核的卷积方法来描述图像补丁。基于核的特征表示可以通过一个简单的随机梯度优化过程来有效地近似，从而产生一个可用于图像检索任务的补丁级描述符。

图像检索是一个具有挑战性的问题，因为同一对象/场景的不同图像可能在视点、照明、缩放、遮挡等方面表现出很大的变化-见图1。

![image-20220710155120700](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710155120700.png)



最先进的实例级检索系统包括三个步骤：

1）兴趣点检测，2）描述和3）匹配。

步骤1)的目标是选择在尺度和视点变化下具有可重复性的关键点——关于探测器的详细比较，见[30,43]。

在步骤2)中选择一个良好的局部表示对于确保对查看条件的鲁棒性是至关重要的。例如，流行SIFT描述符[26]对于光照变化或小旋转是鲁棒的。

至于步骤3)，目标是在两个补丁集之间定义一个合适的度量。为了避免匹配单个补丁的成本，已经提出了可扩展的替代方案，以编码和聚合局部补丁统计数据，如单词袋[41]和VLAD[19]。在这项工作中，我们关注于步骤2)，即描述步骤，而我们依赖于最先进的组件来进行检测和匹配步骤。



我们的灵感来自于在图像分类[22]中使用的深度卷积神经网络(CNNs)[23]输出的表达性特征表示。CNN的中间层输出的特征可以用作图像高度描述符[10]，它可以转移到各种任务中——参见[3,13,31]。最近，有人提出了是否可以从这种架构中派生出合适的补丁级描述符的问题。[25,12,39]通过比较SIFT描述符，为这个问题提供了一个初步的积极答案。虽然这些作品表现出显著的差异，值得注意的是，它们都依赖于监督学习过程。

虽然倒数第二层输出合适的图像一级描述符[3,13,31]，但前一层的输出，通常是第4层，实际上更适合获得表达性的补丁级描述符，如在[25]中注意到的。如[47]所示，与后面的层相比，早期的层倾向于编码更多与任务无关的信息。特别是，无论任务、目标函数或监督水平如何，第一层学习到的过滤器往往是相似的。这引发了以下问题：监督学习是否需要获得良好的局部卷积特征用于补丁匹配和图像检索？                                

我们的贡献是基于卷积核网络(CKNs)[27]的补丁描述符Patch-CKN家族。ckn最初被引入用于[27]中的图像分类。

我们引入了一种基于卷积匹配内核的内核特征映射的补丁特征表示，因此不依赖于示例或标签。可以计算有限维显式特征嵌入来近似该核特征映射[34,44,27]。我们提出了一个快速和简单的程序来计算一个显式的特征嵌入，使用随机子采样的补丁，适用于大规模的实验。实验表明，与监督cnn相比，PatchCKN提供了具有竞争力的补丁级描述符。

一些研究集中在学习补丁表示[7,46]，但很少分析提高补丁检索对图像检索性能的影响。为此，我们引入了一个新的数据集“RomePatches”，使用图像和[1]的三维重建。“罗马补丁”的16KFlickr图像代表了罗马66个不同地点的景色。三维重建提供了稀疏的补丁匹配，产生了我们的补丁检索数据集的地面真相。这允许将补丁任务和图像检索任务的性能改进联系起来。简而言之，我们的主要贡献有方面：

1.我们提出了一个基于CKN架构[27]的补丁描述符，使用一个快速和简单的随机程序来计算一个显式的特征嵌入。 

2.我们引入并提供了一个名为“罗马补丁”的数据集，用于评估补丁和图像检索，从而系统地研究补丁匹配与图像检索性能之间的相关性。 3.我们表明，为了进行补丁和图像检索，可以在没有监督的情况下学习竞争的补丁级描述符，因此与以前的监督替代方案[25,11]相比，只需要计算和注释成本的一小部分。

# 2.相关工作

我们的文献综述集中在与我们最接近的工作上：浅层patch描述符、图像检索的深度学习和patch描述的深度学习。

**Traditional patch descriptors.**

在各种标准补丁描述符中，SIFT[26]是应用最广泛的。SIFT被解释为一个卷积网，它是一个两层的体系结构，第一层计算补丁梯度方向，在第二层中平均合并。SIFT已成功应用于许多任务，如立体匹配[1]、基于内容的检索[16]或分类[33]。米科拉奇克等人[29]提供了局部描述符的详细调查，并证明了SIFT的优良性能。改进的本地描述符包括BRIEF[8]和LIOP[45]。所有这些描述符都是手工制作的，并通过相对较少的参数的网格搜索进行优化。当要设置的参数数量较大时，如果方法不可行，需要从数据中学习最优参数化。

大多数工作都是在手工制作的描述符学习上使用监督。Brown等人[7,46]设计了一个匹配的数据集，该模型由运动结构获得，描述符由几个现有的部分组成，包括但不限于SIFT、GLOH[29]和Daisy[42]。我们不包括他们的数据集在我们的实验中，由于在管道的早期阶段的显著差异，因为多视图立体声对应数据集只包含三个位置的少量图像，使用灰度补丁提取（在这个工作中我们利用额外的颜色信息），它们是用与我们不兼容的探测器（DoG而不是Hessian-affifine）提取的。

Philbin等人[37]学习了一个针对SIFT描述符的马氏度量，以补偿二值化误差，在基于实例的检索中取得了很好的结果。西蒙扬等人[40]提出了“池区域”描述符并学习其参数，以及使用随机优化的线性投影。他们的学习目标可以看作是一个凸优化问题，而这不是经典卷积网络的情况。

一个例外是[5]，它提供了SIFT的匹配核解释，以及一系列核描述符，其参数以无监督的方式学习。我们引入的Patch-CKN推广了核描述符；所提出的计算显式特征嵌入的过程更快、更简单。

**Deep learning for image retrieval.**

有一个CNN在一个足够大的标记集上学习，如ImageNet[9]，其中间层的输出可以用作各种各样的任务，包括图像检索[3,38]——这项工作的重点。通常选择一个全连接层的输出，因为它是紧凑的，通常是4096d。然而，全局CNN描述符缺乏几何不变性[14]，所以它们产生的结果低于最先进的实例级图像检索。因此，有人提出了改进的建议。

在[38,14]中，提取了不同尺度和位置的CNN响应。我们继续进行类似的操作，但是我们用一个补丁检测器代替了（粗的）密集的网格。这是[38,14]和我们的工作之间有一些重要的区别。虽然[14,38]使用倒数第二层的输出作为补丁描述符，但我们在实验中表明，我们可以通过前一层的输出得到改进的结果，这样计算成本更低。在[3]中，作者使用单一的全局CNN描述符进行基于实例的图像检索，并对替代地标数据集进行微调。虽然微调可以改善结果，但很难在地标之外复制这种成功。最后，[21]提出了一种Siamese架构来训练图像检索描述符，但没有在标准检索基准上报告结果。

**Deep patch descriptors.**

最近，[25,12,39]报告了在补丁匹配或补丁分类等任务方面的结果优于SIFT。这三种工作使用不同级别的监督来训练CNN：[25]中的类别标签，[12]中的代理补丁标签（每个类是不同转换下给定的补丁）和[39]中的匹配/非匹配对。这些作品和我们的作品之间有两个关键的区别。首先，他们关注于补丁级别的指标，而不是实际的图像检索。其次，更重要的是，尽管所有这些方法都需要某种监督，但我们表明，我们的Patch-CKN在不需要监督的情况下，在补丁匹配和图像检索方面都具有竞争力的性能。特别是，对于[25,39]，我们不需要昂贵的标签。与[12]相比，我们不需要在类的定义（即转换集）中做出任意的选择

![image-20220710163157914](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710163157914.png)

# 3.**Image Retrieval Pipeline**

我们简要介绍了三步管道：兴趣点检测、补丁描述和补丁匹配

**Interest point detection.**

兴趣点检测器提供了对某些图像转换的位置不变性。这确保了同一场景的两个视图，即使视点或照明发生了变化，也可以共享相似的“兴趣点”，请参见[30]对探测器的回顾。我们使用流行的Hessian-Affifine（黑森-仿射）探测器[28]。其思想是在其特征尺度上提取点，并为每个点估计一个仿射不变的局部区域，见图1。旋转不变性是通过旋转patches来对齐占主导地位的梯度方向。这就产生了一组与局部仿射不变区域相关联的兴趣点。

**Interest point description.**

给定将仿射区域映射到固定大小的平方得到的归一化patches M，计算其在欧几里得空间中的特征表示φ(M)。该表示方法对探测器没有覆盖的扰动（照明变化、小旋转、模糊、……）具有鲁棒性。

**Patch matching.**

由于匹配所有可能的补丁对太昂贵，我们遵循标准实践，将补丁描述符进行编码，并使用VLAD表示[18]将它们聚合为一个固定长度的图像描述符。给定由k个质心{c1，...，ck}组成的特征空间的聚类，VLAD将一组描述符编码为相对于它们所分配的质心的总位移。然后对VLAD描述符应用指数为0.5的功率归一化，以及L2归一化

# **4. Convolutional Descriptors**

我们使用卷积特征来编码固定大小的图像补丁（大小为51×51像素）。cnn通常接受分类监督的训练。

这可以通过以下两种方式扩展到图像检索：

(i)对局部描述符进行编码，该模型已被训练过一个不相关的图像分类任务，见第4.1节；

(ii)设计一个尽可能与图像检索相关的替代分类问题；

(iii)使用无监督学习，如卷积核网络，见Sec。4.2.

## **4.1. Convolutional Neural Networks**

卷积神经网络通过一系列简单的操作或层来转换输入图像。每一层执行一个线性操作，然后是一个点态非线性。形式上，对于以向量表示的某些图像x，CNN的输出f(x)为

![image-20220710164616488](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710164616488.png)

其中，术语Wk是对应于线性操作的矩阵，函数σk是点态非线性函数，例如，s型或修正线性单位，而函数γk执行降采样操作（特征池）。对于卷积层，矩阵Wk具有特定的结构，对应于空间映射的卷积，如图2所示。当它们致密且无结构化时，该层被称为“完全连接”。

![image-20220710164819976](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710164819976.png)

**Learning from category labels**

最受欢迎的场外CNN是AlexNet[22]，它赢得了2012年的ImageNet挑战。AlexNet有7层：前五层是卷积的，最后一层是完全连接的。该网络被设计用于处理大小为224×224的图像，但卷积层可以输入更小的输入来生成1x1的映射，我们可以使用它们作为低维补丁描述符——见表3中的“覆盖”列。为了确保所有方法之间的公平比较，我们重新调整补丁，以总是产生一个1×1的地图。

**Learning from surrogate labels.**

大多数cnn，如AlexNet，使用干扰版本的训练patches来增强数据集，以学习（1）中的过滤器Wk。

[11,12]的作者使用“虚拟补丁”，作为随机提取的补丁的转换，以回到一个分类问题。

同一补丁的转换版本共享相同的标签，从而定义代理类。

对于一组补丁P和一组转换T，数据集由所有τ(p)，(τ，p)∈T×P组成。

在本文中，我们通过使用与[12]中相同的架构和过滤器值，称为PhilippNet，来评估这个策略。该网络有三个卷积层和一个完全连接的层，以64x64补丁作为输入，产生512维输出

## **4.2. Convolutional Kernels Networks**

ckn具有与等式中呈现的经典cnn具有相同的结构（1）和在图2中。

cnn的特征表示依赖于学习的过滤器，因此以数据依赖的方式定义。

我们在这里定义了一个基于内核（特征）映射的特征表示。因此，这个特性表示的确切版本是与数据无关的。一个显式的核（特征）映射可以计算出来近似它[34,44,27]，以提高计算效率。为此目的，我们提出了一个快速和简单的程序，使用补丁的子采样和随机梯度优化，产生一个输出补丁描述符的CKN。

设M和M‘是两个大小为m×m的补丁(本文中为m=51)，而$Ω=\{1，...，m\}^2$是像素位置的集合。让我们也考虑一个固定的子补丁大小，并用$p_z$表示M的子补丁中心位置z∈Ω($p_z^{'}$是子补丁来自M’)

**Single-layer kernel defifinition.**

我们考虑以下内核[27]：

![image-20220710170102065](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710170102065.png)

![image-20220710170108816](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710170108816.png)

α1和β1是两个核超参数，||·||表示通常的L2范数，$p˜_z$和$p'˜z$是子补丁$p_z$和$p_z^{'}$的L2标准化版本。

相应的内核（特征）映射为补丁和图像定义了一个特征表示。此外，该内核是一个匹配的内核。因此，内核通过超参数的选择提供了可调的不变性，并产生非常适合自然图像的分层卷积表示。

**Kernel embedding approximation.**

由于（2-3）的精确计算是overwhelming的，Mairal等人提出了一个显式的有限维嵌入[34,44]来近似它。[27]的嵌入保持了二维的空间结构，类似于CNN的特征图。

对于单层CKN，[27]的近似值为：

![image-20220710170451852](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710170451852.png)

![image-20220710170514930](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710170514930.png)

其中Ω1是Ω的子集，如[27]中，w和η是学习参数。有两种不同的近似，一种是在由|Ω1|≤|Ω|定义的子采样中，它对应于CNN池化操作的步幅，另一种是在子补丁的高斯核的嵌入中：

![image-20220710170553546](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710170553546.png)

由于K1(M，M)是匹配核项的和，我们可以通过求解一个优化问题在子补丁级别上近似它。与等式4中的原始配方相比在[27]中，我们引入了变量的变化

![image-20220710170642572](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710170642572.png)

并且，考虑一个n对子补丁的样本{($p_i$，$p'_i$)}i=1，...，n，我们求解：

![image-20220710170736296](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710170736296.png)

我们使用随机梯度优化来找到这个（非凸）目标的一个平稳点。这比原来的L-BFGS优化器[27]要快得多；见Sec 6.

**Multi-layer CKN kernel.**

一个内核可以覆盖在单个内核上，以实现“更深”和可能更好的特性表示[4]。给定一个输入补丁M，单层CKN定义了一个近似的f1(M)，它可以被解释为一个空间地图。可以像我们对输入补丁所做的一样，去细化这个映射上的内核k2。为此，我们简单地定义了一个补丁大小，新的超参数β2和α2，并在前一节的所有方程中将M，M'替换为f1(M)，f1(M')。

图3给出了相应的两层卷积核的说明。训练多层CKN自然是连续的，一层接一层

![image-20220710170837426](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710170837426.png)

**Input types.**

我们研究了ckn的三种可能的输入。

第一个，CKN-raw，直接将原始的RGB补丁发送给网络。该方案捕获色调信息，在某些情况下是一个缺点。

CKN-white包括对CKN第一层的每个子补丁进行预处理，通过减去它们的平均颜色，并使用PCA白化，并在初始补丁的所有子补丁上学习PCA。这只响应子补丁内部的局部变化，并使网络对颜色更加不变。

CKN-grad对颜色是完全不变的。它是沿每个空间维度的梯度用1×1的子补丁。也就是说，这个第一层的子补丁$\widetilde{p}_z$ 是简单的二维的，可以写成pz=(Gx，Gy)。由于特征是归一化的，匹配内核$||\widetilde{p}_z−\widetilde{p}'_{z'}||$的内部部分是直接连接到两个梯度之间的夹角的余弦值，见[5,27]。实际上，具有$n_1$均匀分布方向的核K1的显式近似θj=2jπ/n1，j∈{1，...，n1}写道：

![image-20220710171207938](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710171207938.png)

![image-20220710171237408](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710171237408.png)

这个公式可以解释为大小为n1的“直方图”中梯度方向的 soft-binning。为了确保在每个箱子中都有足够的分布，我们设置了

![image-20220710171303473](D:\文献阅读\Recent deveopments of CBIR\image\image-20220710171303473.png)