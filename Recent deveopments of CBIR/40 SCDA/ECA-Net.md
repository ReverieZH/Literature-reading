# ECA-Net: Effificient Channel Attention for Deep Convolutional Neural Networks

近年来，通道注意机制在提高深度卷积神经网络(CNNs)的性能方面具有巨大的潜力

然而，大多数现有的方法都致力于开发更复杂的注意力模块，以获得更好的性能，这不可避免地增加了模型的复杂性。

为了克服性能和复杂性权衡的悖论，本文提出了一个高效通道注意(ECA)模块，该模块只涉及少量参数，同时带来明显的性能增益。

通过对SENet中的通道注意模块的解剖，我们的经验表明，避免降维对于学习通道注意很重要，适当的跨通道交互可以在保证性能的同时保持模型的复杂度。

因此，我们提出了一种不需要降维的局部交叉通道交互策略，该策略可以通过一维卷积有效地实现。此外，我们开发了一种自适应地选择一维卷积的核大小的方法，以确定局部跨信道交互作用的覆盖范围。

提出的ECA模块是有效的，例如，我们的模块对ResNet50主干的参数和计算分别为80 vs 24.37M和4.7e-4GFLOPs和3.86GFLOPs，在Top-1精度方面性能提高超过2%。我们利用ResNets为骨干，对图像分类、目标检测和实例分割方面的eca模块进行了广泛的评估。实验结果表明，该模块的工作效率更高，但性能更好。

# 1. Introduction

深度卷积神经网络(cnn)已经广泛应用于计算机视觉界，并在广泛的任务中取得了很大的进展，如im年龄分类，目标检测和语义分割。

从开创性的AlexNet[17]开始，许多研究不断被研究，以进一步提高深度CNNs[29,30,11,15,19,20,32]的性能。近年来，将通道注意力纳入卷积块引起了人们的兴趣，在[14,33,13,4,9,18,7]方面表现出巨大的潜力。其中一种具有代表性的方法是squeeze-and-excitation

networks (SENet)[14]，它可以学习每个卷积块的信道注意，为各种深度CNN架构带来明显的性能增益。

在SENet[14]中设置了挤压（即特征聚合）和激励（即特征重新校准）之后，一些研究通过捕获更复杂的信道依赖关系[33,4,9,7]或与额外的空间注意[33,13,7]结合来改进SE块。虽然这些方法取得了较高的精度，但往往带来较高的模型复杂度和较大的计算负担。与上述以更高的模型复杂度为代价获得更好的性能的方法不同，本文关注的是一个问题：能否以更有效的方式学习有效的通道注意？

为了回答这个问题，我们首先重新访问SENet中的通道注意模块。具体来说，给定输入特征，SE块首先对每个通道独立使用一个全局平均池，然后使用两个非线性的全连通(FC)层，然后使用一个sigmoid函数来生成通道权值。这两个FC层被设计用来捕获非线性的跨通道交互作用，其中涉及到降维以控制模型的复杂性。虽然该策略在后续的通道注意模块[33,13,9]中被广泛应用，但我们的实证研究表明，降维对通道注意预测带来了副作用，并且捕获所有通道之间的依赖关系是低效和不必要的。

因此，本文提出了一种用于深度cnn的高效通道注意(ECA)模块，它避免了降维，并有效地捕获了跨通道交互。

如图2所示，在没有降维的情况下进行通道级全局平均池化后，我们的ECA通过考虑每个通道及其k个邻居来捕获局部跨通道交互。

![image-20220726144030859](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726144030859.png)

证明了该方法的效率和有效性。请注意，我们的ECA可以通过大小为k的快速一维卷积有效地实现，其中核大小k表示局部跨通道交互的覆盖范围，即有多少邻居参与了一个通道的注意预测。为了避免通过交叉验证手动调优k，我们开发了一种自适应确定k的方法，其中交互的覆盖率(即核大小k)与信道维度成正比。

如图1和表3所示对于骨干模型[11]，深度cnn与我们的ECA模块(称为ECA- net)引入非常少的额外参数和微不足道的计算，而没有带来表的性能增益。例如，对于具有24.37M参数和3.86GFLOPs的ResNet-50，ECA-Net50的附加参数和计算分别为80和4.7e-4GFLOPs；同时，ECA-Net50在前1精度方面比ResNet-50高出2.28%。

表1总结了现有的注意模块，包括通道降维(DR)、交叉通道交互和轻量级模型，我们可以看到我们的ECA模块通过避免通道降维来学习，同时以极其轻量级的方式捕获跨通道交互的方式，学习有效的通道注意。为了评估我们的方法，我们在ImageNet-1K[6]和MSCOCO[23]上的各种任务中进行了实验。

![image-20220726144732749](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726144732749.png)

本文的贡献总结如下。（1）我们分析了SE块，并通过经验证明了避免降维和适当的跨通道交互对于学习有效和有效的通道注意非常重要。（2）基于上述分析，我们尝试通过提出高效通道注意(ECA)来开发一个针对深度cnn的极轻便通道注意模块，该模块在明显改进的同时几乎增加了模型的复杂性。（3）在ImageNet-1K和MSCOCO上的实验结果表明，我们的方法具有比现有的方法更低的模型复杂度，同时实现了非常有竞争力的性能

# 3. Proposed Method

在本节中，我们首先重新访问SENet[14]中的通道注意模块(即SE块)。然后，我们通过分析降维和跨通道交互作用的影响，对SE块进行了经验诊断。这促使我们提出我们的ECA模块。此外，我们还开发了一种自适应确定ECA参数的方法，并最后展示了如何将其用于深度cnn。

## 3.1. Revisiting Channel Attention in SE Block

设一个卷积块的输出为$X∈R^{W×H×C}$，其中W、H和C为宽度、高度和信道尺寸（即滤波器的数量）。因此，SE块中通道的权值可以计算为

![image-20220726144952617](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726144952617.png)

![image-20220726145026503](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726145026503.png)

g(X )是通道方向的全局平均池(GAP)，σ是一个 Sigmoid函数。

y = g(X )，

![image-20220726163804028](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726163804028.png)

为了避免较高的模型复杂度，W1和W2的大小分别设置为$C×(\frac Cr)$和$(\frac Cr)×C$

我们可以看到，f{W1，W2}涉及到通道注意块的所有参数。而在等式（2）中的降维性可以降低模型的复杂性，它破坏了通道与其权值之间的直接对应关系。例如，一个FC层使用所有通道的线性组合来预测每个通道的权重。但在等式.（2）首先将通道特征投射到一个低维空间，然后将它们映射回，使通道与其权重之间的对应关系是间接的。

## 3.2. Effificient Channel Attention (ECA) Module

在重新访问SE块后，我们进行了经验比较，分析了通道降维和跨通道交互作用对通道注意学习的影响。根据这些分析，我们提出了我们的有效通道注意(ECA)模块。

### 3.2.1 Avoiding Dimensionality Reduction

如上所述，等式中的降维（2）使得信道与其权重之间的对应关系是间接的。

为了验证其效果，我们将原始的SE块与它的三个变体(即SE-Var1、SE-Var2和SEVar3)进行了比较，所有这些变体都不进行降维。

![image-20220726165315492](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726165315492.png)

如表2所示，没有参数的SE-Var1仍然优于原始网络，说明信道注意能够提高深度cnn的性能。

同时，SE-var2独立学习每个信道的权值，略优于SE块，但涉及的参数较少。

这表明信道及其权重需要直接对应，而避免降维比考虑非线性信道依赖性更重要。

此外，使用一个单一FC层的SEVar3比在SE块中降维的两个FC层性能更好。以上所有的结果都清楚地表明，避免降维有助于学习有效的通道注意。因此，我们开发了我们的ECA模块。

### 3.2.2 Local Cross-Channel Interaction

给定不降维的聚合特征$y∈R^C$，通道注意可以通过

![image-20220726165938277](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726165938277.png)

W是一个C×C参数矩阵。特别是，对于SE-Var2和SE-Var3，我们有

![image-20220726170015169](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726170015169.png)

SE-Var2的$W{var2}$是一个对角线矩阵，包含C参数；

SE-Var3的$W{var3}$是一个完整的矩阵，涉及C×C参数

如等式中所示（4），关键的区别是SE-Var3考虑跨通道交互，而SEVar2不考虑，因此SE-Var3获得了更好的性能。

这一结果表明，跨通道交互作用有利于学习通道注意。然而，SEVar3需要大量的参数，导致模型的复杂性，特别是对于大通道数。

SE-Var2和SE-Var3之间的一个可能的折衷方案是将$W{var2}$扩展到一个块对角矩阵，即，

![image-20220726170316005](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726170316005.png)

Eq（5）将通道划分为G组，每个组包括C/G通道，并独立学习每个组中的通道注意，以局部方式捕获跨通道交互

因此，它涉及到C2/G参数。从卷积的角度来看，SE-Var2，SEVar3和等式（5）可以分别看作是一个深度可分离的卷积、一个FC层和群卷积。

这里，带有群卷积的SE块（SE-GC）表示为![image-20220726170757652](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726170757652.png)

然而，如[24]所示，过度的组卷积会增加内存访问成本，从而降低计算效率。

此外，如表2所示，不同组的SE-GC没有给SE-Var2带来增益，这表明它不是一个捕获局部跨通道相互作用的有效方案。原因可能是SE-GC完全抛弃了不同组之间的依赖关系。

在本文中，我们探索了另一种捕获局部跨通道交互的方法，旨在保证信息效率和有效性。具体地说，我们使用了一个频带矩阵Wk来学习信道注意，而Wk

![image-20220726170930246](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726170930246.png)

在等式中（6）涉及k个×C参数，通常小于等式 (5).

此外，等式（6）避免了等式(5)中不同群体之间的完全独立 .

如表2所示，在等式（6）中的方法(即ECA-NS)的性能优于等式(5)的SE-GC .至于等式6，yi的权重是通过仅考虑yi与其k个邻居之间的相互作用来计算的，即，

![image-20220726171136496](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726171136496.png)

$Ω^k_i$表示yi的k个相邻通道的集合。

一种更有效的方法是使所有通道共享相同的学习参数，即：

![image-20220726171248099](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726171248099.png)

请注意，这种策略可以很容易地通过一个核大小为k的快速一维卷积来实现，即，

![image-20220726171306565](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726171306565.png)

其中C1D表示一维卷积。

这里是等式中的方法（9）由有效通道注意(ECA)模块调用，它只涉及k个参数。如表2所示，我们使用k=3的ECA模块在模型复杂度更低的情况下获得了类似的与SE-var3模块的结果，通过适当捕获局部跨通道交互，保证了效率和有效性。

### 3.2.3 Coverage of Local Cross-Channel Interaction

由于我们的ECA模块（9）旨在适当地捕获局部跨通道交互，因此需要确定交互的覆盖范围(即一维卷积的核大小k)。在不同的CNN架构中，对于具有不同通道数的卷积块，可以手动调整优化的交互覆盖率。然而，通过交叉验证进行手动调优将花费大量的计算资源。

组卷积已成功采用改进CNN架构[36,34,16]，其中高维（低维）信道涉及长距离（短距离）卷积。

具有相似的原理，交互的覆盖范围(即一维卷积的核大小k)与信道维数C成正比是合理的。换句话说，在k和C之间可能存在一个映射φ：

![image-20220726173325295](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726173325295.png)

最简单的映射是一个线性函数，即φ(k)=γ∗k−b。然而，以线性函数为特征的关系就太有限了。另一方面，众所周知，信道维度C（即滤波器的数量）通常被设置为2的幂。

因此，我们通过将线性函数φ(k)=γ∗k−b扩展到非线性函数，引入了一个可能的解，即：

![image-20220726173510313](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726173510313.png)

然后，给定信道维数C，核大小k可以自适应地确定

![image-20220726173529093](D:\文献阅读\Recent deveopments of CBIR\40 SCDA\image\image-20220726173529093.png)

其中|t|奇数表示t的最接近奇数。在本文中，我们在所有实验中分别将γ和b设为2和1。显然，通过映射ψ，高维通道具有更长范围的相互作用，而低维通道通过使用非线性映射进行更短范围的相互作用