研究表明，在一个大型卷积神经网络的顶层中，由一个图像所调用的激活提供了一个关于该图像的视觉内容的高级描述符。

在本文中，我们研究了这些描述符（神经代码）在图像检索应用中的使用。

在使用几个标准检索基准的实验中，我们建立了，即使卷积神经网络被训练为一个不相关的分类任务（例如图像网络），神经编码也具有竞争力。

我们还评估了当神经代码在与测试时遇到的图像相似的图像数据集上进行重新训练时，神经代码的检索性能的改进。

我们进一步评估了压缩的神经代码的性能，并表明一个简单的PCA压缩提供了非常好的短代码，在许多数据集上提供了最先进的精度。

一般来说，与其他最先进的描述符相比，神经代码对这种压缩更有弹性。

最后，我们证明了在匹配照片对的数据集上训练的鉴别降维进一步提高了pca压缩神经代码的性能。总的来说，我们的定量实验证明了神经代码作为图像检索的视觉描述符的前景。

# 一、**Introduction**

深度卷积神经网络[13]最近极大地提高了图像分类的技术水平[10]，因此引起了计算机视觉界的广泛兴趣。与图像分类问题相关的是图像检索问题，即查找包含与查询图像中相同对象或场景的图像的任务。有人认为，在CNN学习到的分类图像的上层出现的特征可以作为很好的图像检索描述符。特别是，克里热夫斯基等人[10]已经提供了一些定性证据。

在这里，我们专注于建立这些特征（我们称之为神经代码）及其变化的定量性能。

我们首先通过对卷积神经网络中出现的特征进行性能的量化评估来识别image - net[1]类。 

我们首先提供定量评估在训练识别Image-Net [1]类的卷积神经网络中出现的特征的图像检索性能。我们在四个标准基准数据集上衡量这种性能：INRIA Holidays [8]，Oxford Buildings，Oxford Building 105K [19]和the University of Kentucky benchmark (UKB) [16]。也许不足为奇的是, 这些深层的特征表现良好, 但并不比其他最先进的整体特征（例如Fisher矢量）更好。 有趣的是，在不同的检索设置中，CNN不同层的相对性能是不同的，并且标准检索数据集上的最佳性能是通过完全连接的层级结构中间的特征来实现的。

神经编码的良好性能证明了其普遍性，因为我们训练网络的任务（即图像网络类分类）与我们所考虑的检索任务有很大的不同。尽管有这种普遍性的证据，但通过使深度特征适应任务来提高其性能的可能性很明显，而这种适应是论文第二部分的主题。为此，我们组装了一个大规模的图像数据集，其中的类对应于地标（类似于[14]），并使用原始的图像网网络参数作为初始化，在这个集合上重新训练CNN。经过这样的训练，我们观察到在具有类似图像统计数据的数据集上的检索性能有了相当大的提高，如INRIA假日和牛津建筑，而在不相关的UKB数据集上的性能有所下降。

在第二类实验中，我们在不同对象的转盘视图的多视图RGB-D数据集[12]上对初始网络进行了再训练。正如预期的那样，我们观察到在更相关的UKB数据集上的改进，而在其他数据集上的性能下降或保持不变。

最后，我们重点评估神经代码的紧凑版本的性能。我们评估了图像检索的PCA压缩神经编码的性能，并观察到神经编码可以非常大幅度地压缩，例如128维，几乎不会损失检索精度。总的来说，由神经代码引起的PCA压缩造成的退化比由其他整体描述符引起的退化要小得多。这使得神经代码的使用对于大规模检索应用程序特别有吸引力，在这些检索应用程序中，描述符的内存占用通常是主要的瓶颈。

只要将压缩推到极致，例如16维，就会导致相当大的退化。我们在自动收集的大量描绘相同物体的照片对(约900K对)上进行了判别降维实验。当在这样的数据集上进行训练时，鉴别降维的性能明显优于PCA，并且对非常短的代码获得了较高的检索精度(例如，牛津建筑上的16维特征的0.368mAP)。

# **三、Using Pretrained Neural Codes**

**Deep convolutional architecture.**

在本节中，我们评估通过将图像通过深卷积网络而获得的神经编码的性能，该网络经过训练以对1000个Image-Net类进行分类[10]。特别是，我们使用自己重新实现的系统[10]。该模型包括五个卷积层，每个卷积层包括卷积、整流线性(ReLU)变换(f(x) = max(x，0))和最大池化（层1,2和5）。在该体系结构的顶部是三个完全连接的层("层6","层7","层8")，其将前一层的输出作为输入，乘以权重矩阵，并且在层6和7的情况应用整流线性变换。训练网络，使得第8层输出对应于类标签的单一编码。在训练期间使用softmax损失。ILSVRC数据集[1]的训练结果与[10]中报告的单个CNN的结果非常吻合（更确切地说，得到的准确度比其更低2％）。我们的网络架构如图1所示。


![image-20220705155943753](D:\文献阅读\Recent deveopments of CBIR\image\image-20220705155943753.png)

该网络适用于224×224图像。其他尺寸的图像大小调整为224×224（无裁剪）。CNN结构是前馈的，并且给定一副图像I，它产生一系列层激活。我们用L5(I)，L6(I)和L7(I)表示在ReLU变换之前相应层的激活（输出）。当然，这些高维向量中的每一个表示输入图像的一个深层描述符（神经编码）。


**Benchmark datasets**

我们在下面列出了在四个标准数据集上评估神经代码的性能。表1给出了基于整体描述符（维数高达32K）的表现最佳的方法的结果。

![image-20220705160418845](D:\文献阅读\Recent deveopments of CBIR\image\image-20220705160418845.png)

**Results.**

使用ILSVRC类训练的网络生成的神经编码的结果在表1的中间部分给出。所有结果都是在L2标准化神经编码上使用L2距离获得的。我们给出了对应于每个层5,6,7的结果。我们还尝试了第8层的输出（对应于ILSVRC类概率，因此与先前使用类概率作为描述符的工作密切相关），但是它的输出结果更糟糕（比Holidays第5层的mAP更差0.02）。


在所有层中，第6层表现最好，但是并非对于所有查询而言它都最好（参见图2和图3）。尽管如此，使用代码的简单组合（例如，求和或级联）获得的结果比单独的L6(I)-代码更差，并且我们实验的更复杂的非线性组合规则仅给出了微小的改进。

总的来说，使用L6(I)-代码获得的结果在同一个范围内，但与现有技术相比并不优越。 然而，考虑到ILSVRC分类任务与此处考虑的检索任务之间存在差异，它们的强大性能仍然非常出色。

![image-20220705160808940](D:\文献阅读\Recent deveopments of CBIR\image\image-20220705160808940.png)

![image-20220705160818275](D:\文献阅读\Recent deveopments of CBIR\image\image-20220705160818275.png)

# 四、 **Retrained neural codes**

提高神经代码性能的一个简单的想法是在数据集上用与测试时考虑的数据集更相关的图像统计数据和类来重新训练卷积体系结构。

**The Landmarks dataset**

我们首先关注于收集与地标性类型的数据集（假日和牛津建筑）相关的数据集。收集这样的数据集是一项艰巨的任务，我们为此选择了一种（半）自动化的方法。我们首先选择10000个最具里程碑意义的维基百科页面（过去一个月）。对于每个页面，我们使用页面的标题作为对Yandex图像搜索引擎1的查询，然后下载1000张响应查询返回的顶级图像（如果查询返回的图像更少，则更少）。

在第二阶段，我们通过观察响应顶部的数百张照片以及从剩余图像（900或更少）均匀采样的另外一百张照片来观察返回的图像。然后我们手动将下载的列表分类为以下三个类别之一：(1)“take all”（数百个中至少80％是相关的，即标记的实际照片），(2)“take top”（前100个中至少有80％是相关的，但是接下来的100个有超过20％是不相关的图像，包括logo，地图，肖像，错误的场景/对象），(3)“unsuitable”（超过20％不相关的图像在前一百个图像内）。总的来说，通过这种方式，我们发现了252个“take all”的图像和420个“take top”的图像。图4显示了收集的数据集中两个典型的类示例。然后，我们从这些类中汇总数据集，为每个查询获取前1000个图像（用于“take all”类）或前100个图像（用于“take top”类）。

总的来说，得到的数据集有672个类和213,678个图像。在收集过程中，我们排除了与Oxford相关的查询，我们还从最终数据集中删除了几个带有Holidays数据集的重复数据集。我们还在本页下面提供了查询和URL列表。

![image-20220705162105262](D:\文献阅读\Recent deveopments of CBIR\image\image-20220705162105262.png)

因此，我们收集地标数据集的方法与使用Flickr爬取以全自动方式组装类似数据集的[14]的方法不同。由图像搜索引擎索引的图像和用户标记的图像的统计数据是不同的，因此使用Flickr爬取的数据集尝试自适应将是有趣的。

然后，我们使用收集的数据集来训练CNN，其结构与ILSVRC相同（除了我们将输出节点数改为672）。我们通过原始的ILSVRC CNN来初始化我们的模型（最后一层除外）。 否则，训练就与原始网络相同
**Results for retrained neural codes.** 

表1中给出了在地标数据集上重新训练的网络产生的神经编码的结果。正如预期的那样，与原始神经编码的差异是与地标图像和特定检索数据集之间的相似性有关。因此，Oxford 和 Oxford 105K数据集有了很大的改进，这些数据集也是基于具有标记的照片。Holiday数据集的改进较小但仍然非常可观。在Holidays数据集上改编的L6(I)特征的性能优于以前发布的基于整体特征的系统（除非考虑更高的维度，如[22]中所述）。

图5显示了使用原始和重新训练的神经编码获得的结果的代表性检索示例。我们还尝试在随机初始化（即从头开始训练）的带有标记的数据集上训练CNN，但与ILSVRC相比，由于训练图像的数量较少和更高比例的无关图像而观察到性能不佳。

有趣的是，虽然我们通过在Landmarks数据集上重新训练CNN来获得改进，但是通过在SUN数据集上重新训练CNN，并没有获得在原始神经编码上的改进[25]。显然，这是因为每个SUN类仍然对应于具有相同使用类型的不同场景，而Landmark数据集以及Holidays和Oxford数据集中的每个类对应于相同的对象（例如建筑物）。

**Adaptation on the turntable sequences.** 

在对Landmarks数据集进行再训练后，UKB数据集的性能下降。这反映了以下事实：UKB数据集中的类（对应于不同小对象的多个室内视图）与ILSVRC中的某些类更相似，而不是标记的图像。为了证实这一点，我们进行了第二次再训练实验，其中我们使用了多视图RGB-D数据集[12]，其中包含300个家用电器的转盘视图。我们将每个对象视为一个单独的类，并为每个类抽取200个图像。我们在60,000张图像（深度通道信息被丢弃）的数据集上重新训练网络（再次由ILSVRC CNN初始化）。我们再一次观察到（表1）这种再训练提高了相关数据集的检索性能，因为UKB的准确率从3.43增加到3.56。在不相关数据集（Oxford，Oxford-105K）上的性能下降。

# 五、 **Compressed neural codes**

由于我们实验中的神经编码是高维的（例如对于L6(I)来说是4096），尽管比其他现有技术的整体描述符具有更低的维度，但是出现了它们有效压缩的问题。在本节中，我们将评估两种不同的压缩策略。首先，我们研究神经编码的效率如何随着常见的基于PCA的压缩而降低。一个重要的发现是这种退化是相当优美的。其次，我们基于判别性降维来评估更复杂的程序。我们将评估集中在L6(I)上，因为与第六层相关的神经编码的性能始终比来自其他层的代码更好。
PCA压缩。我们首先评估PCA压缩后不同版本的神经编码对不同维数的性能(表2)。在这里，PCA训练是对来自Landmark数据集的100,000个随机图像进行的。

针对不同PCA压缩率的神经编码L6(I)的质量在表2中给出。总体而言，PCA工作得非常好。因此，神经编码可以被压缩到256或甚至128维，几乎在没有任何损失的情况下。重新训练代码的优点在所有压缩率下都会持续存在。表3进一步比较了压缩到128维的不同整体描述符，因为在以前的工作中选择了这个维度进行比较。对于Oxford和Holidays数据集，地标再训练神经编码在低维全局描述符中提供了新的最新技术。
![image-20220705163056028](D:\文献阅读\Recent deveopments of CBIR\image\image-20220705163056028.png)

![image-20220705163144966](D:\文献阅读\Recent deveopments of CBIR\image\image-20220705163144966-16570099071331.png)

**Discriminative dimensionality reduction**

本节中，我们通过学习低秩投影矩阵W进一步进行判别维数降低。该学习的目的是在对应的图像包含相同对象时使代码之间的距离较小，而在其它情况下使代码之间的距离较大，从而实现对诸如视点变化等干扰因素的额外容忍。对于这种学习，我们收集了许多包含相同对象的图像对。 同样，这里的难点是收集一组不同的对。
为了获得这样的数据集，我们在Landmark数据集的相同类中对图像对进行采样。我们使用标准图像匹配管道（SIFT +最近邻匹配与第二最佳邻居测试[15] + RANSAC验证[5]）建立匹配图。管道应用于属于同一地标的所有图像对。一旦构建了地标的图形，我们就拍摄一对照片，这些照片在图表中至少共享一个邻居但不是邻居本身（以确保我们不会将训练过程集中在近似重复上）。通过这样的过程，我们获得900K不同的图像对（图7）。我们进一步贪婪地选择100K对的子集，使得每张照片在这样的子集中最多出现一次，并使用该对子集进行训练。

![image-20220705164033202](D:\文献阅读\Recent deveopments of CBIR\image\image-20220705164033202.png)

表4比较了Oxford数据集非重训练代码的两种压缩策略(PCA和判别约简)的结果。可以看出，对于极度压缩的16维码，判别维数约简能获得最大的增益。我们还评估了在地标数据集上重新训练的神经编码的判别维数减少。然而，在这种情况下，我们并没有观察到判别维数减少的任何额外改进，可能是因为网络再训练和判别维数降低是使用重叠训练数据进行的。

![image-20220705164257171](D:\文献阅读\Recent deveopments of CBIR\image\image-20220705164257171.png)

# 六、Conclusion

我们已经评估了图像检索应用程序中深度神经编码的性能。可以从我们的实验中得出以下几个结论和观察结果。

首先，正如所预期的那样，即使使用经过训练的CNN执行分类任务，并且当训练数据集和检索数据集彼此非常不同时，神经编码也执行得很好。不出所料，当CNN在与检索数据集更相关的图片上重新训练时，可以进一步改善这种性能。

我们注意到在检索准确性方面存在明显的改进空间，因为所有图像都被下采样到低分辨率（224×224），因此丢失了很多关于纹理的信息，这些信息可能是非常重要的。作为待改进的一个方面，我们使用Fisher Vectors进行的实验表明，在类似情况下，它们在Holidays数据集上的性能下降约为0.03 mAP。

有趣的是，也许是出乎意料的是，最好的性能不是出现在网络的最顶层，而是出现在输出层的前两层内。即使CNN在相关图像上重新训练之后，这种效果仍然存在。我们推测，这是因为顶层对分类任务调优太多，而底层对干扰因素没有获得足够的不变性。

我们还研究了压缩神经编码的性能，其中普通PCA或具有判别维数减少的PCA组合导致非常短的代码具有非常好的（最先进的）性能。一个重要的结果是PCA影响神经编码的性能远低于VLAD，Fisher矢量或三角测量嵌入。一种可能的解释是，通过网络传递图像会丢弃与分类（和检索）无关的大部分信息。因此，来自更深层的基于CNN的神经码保留比无监督的基于聚合的表示更少（无用）的信息。 因此，PCA压缩对神经编码更有效。

一个可能有趣的研究方向是，是否可以通过使用匹配图像对来训练整个深层结构，从而直接获得良好的神经编码（而不是使用分类性能作为训练目标），例如， 使用[3]中的siamese结构。自动收集具有足够多样性的合适训练集合本身就是一项有趣的任务。最后，我们注意到，通过选择用于生成代码的网络层的大小而不是事后过程，可以实现维度减少到所需的维度。


