https://blog.51cto.com/u_15404184/4309470



最近，建立在卷积神经网络(CNN)上的图像表示已经被证明为图像搜索提供了有效的描述符，作为短向量表示优于前CNN特征。

然而，这种模型与几何感知的重新排序方法并不兼容，并且在某些特定的对象检索基准上，仍然优于依赖于精确描述符匹配、几何重新排序或查询扩展的传统图像搜索系统。

这项工作重新访问了两个检索阶段，即初始搜索和重新排序，通过使用相同的原始信息来自CNN。

我们建立了紧凑的特征向量，它可以编码几个图像区域，而不需要向网络输入多个输入。

此外，我们扩展了积分图像来处理卷积层激活上的最大池化，允许我们有效地定位匹配的对象。

生成的边界框最终用于图像重新排序。

因此，本文显著改进了现有的基于cnn的识别管道：我们首次报告了在具有挑战性的Oxford5k和Paris6k数据集上与传统方法竞争的结果

 

# 1. 引言

目前最先进的方法来源于Sivic和齐瑟曼（2003）的单词包模型，它们的成功主要归功于局部不变特性(Lowe，2004)和大型视觉码本(Philbinetal.，2007)。这些方法通常由一个初始过滤阶段组成，其中所有的数据库图像都根据与查询图像的相似性进行排序，以及第二个重新排序阶段，它细化了排名最高的元素的搜索结果。

过滤阶段在几个方面得到了改进，例如合并弱几何信息(J‘egou等人，2010)，使用局部描述符的紧凑近似(J’egou等人，2010)，或学习智能码本(Mikulik等人，2013；阿弗里西斯&卡兰蒂迪斯，2012)。在这种情况下，局部描述符是单独匹配和选择性匹配函数(Tolias等人，2015；Tao等人，2014)提高了搜索质量。

几何匹配模型(Philbin等人，2007；Avrithis&Tolias，2014)通常以成对的方式应用在图像短列表的重新排序阶段。

查询扩展方法显著提高了性能(Chumetal.，2011)，但代价是查询时间的增加。

卷积神经网络(CNN)和使用中间层激活作为特征向量(Donahueetal.，2013)所取得的最新进展为图像或特定对象检索的竞争表示创造了机会，而不仅仅是分类任务。已经有一些研究作品对该研究方向进行了研究，例如基于完全连接（Babenko等人，2014年；龚等人，2014年）或卷积层（Razavian等人，2014年b；阿兹普等人，2014年；巴宾科和伦皮茨基，2015年）

基于cnn的特征的性能已经迅速提高，可以竞争甚至超过聚合局部特征的前cnn作品(J‘egou等人，2012；Radenovi’c等人，2015)。特别是，激活卷积层之后进行全局最大池化操作(Azizpouretal.，2014)会产生高度具有竞争力的紧凑图像表示。一个限制是，这种方法与最终重新排序阶段中涉及的几何感知模型不兼容。

这项工作用基于cnn的特性重新访问了过滤和重新排序的阶段。我们做出了以下三项贡献。

- 首先，我们提出一个紧凑的图像表示来自卷积层激活编码多个图像区域不需要补充多个输入网络，最近Fast-RCNN（吉希克，2015）和Faster-RCNN(任etal.，2015)方法，但这里针对特定的对象检索。底层的原始表示法用于所有阶段（初始检索和重新排序）。
- 其次，我们使用generalized mean(Doll‘aretal.，2009)来实现积分图像和最大池化的使用。这种有效的方法直接在CNN激活的2D映射中用于特定的对象定位（见图1）。![image-20220713175931075](D:\文献阅读\Recent deveopments of CBIR\image\image-20220713175931075.png)
- 第三，我们的定位方法用于图像重新排序，并引导我们定义一个简单而有效的查询扩展方法。



这些方法是互补的，当结合起来时，首次产生了一个系统，它在牛津和巴黎的建筑基准上与基于本地特征的最先进的重新排序方法相竞争。我们的方法比以往基于CNN的方法表现得更好，同时在实践中效率更高。



# 3. 背景

我们考虑一个预先训练过的CNN，并丢弃所有完全连接的层。

给定一个大小为WI×HI的输入图像I，卷积层的激活（响应）形成一个W×H×K维的三维张量，其中K是输出特征通道的数量，即多维滤波器。

空间分辨率W×H取决于网络结构、检测的层和输入图像分辨率。我们假设应用Rectified Linear Units(ReLU)作为最后一步，以保证所有的元素都是非负的。

我们将这个响应的3D张量表示为一组二2D特征通道响应$X=\{X_i\}，i=1…K$，其中$X_i$是二维张量，表示有效空间位置的集合Ω上的第i个特征通道的响应，$X_i(p)$是特定位置p的响应。因此，由所有位置的空间最大池化构建的特征向量(Azizpouretal.，2014)由

![image-20220714135054430](D:\文献阅读\Recent deveopments of CBIR\image\image-20220714135054430.png)

**Maximum activations of convolutions (MAC)**

将两幅图像用上述产生的k维向量的余弦相似度进行了比较。这种表示被称为MAC，它不编码激活的位置（不像完全连接层的激活）

由于最大池化在大小为W×h的单个区域上运行，它编码了每个卷积滤波器的最大“局部”响应，因此是平移不变的。在下面的所有内容中，我们考虑被检查网络的最后一个卷积层。

图2可视化了对图像相似性贡献最大的补丁。由于重复的结构，它们要么对应于相同的物体部分，要么是相似的部分。我们通过简单地从输入图像中减去平均像素值(Iandolaetal.，2014)，从任何分辨率或高宽比的输入图像中提取MAC。不需要剪裁或改变长宽比

![image-20220714135817784](D:\文献阅读\Recent deveopments of CBIR\image\image-20220714135817784.png)

在单个单元格上执行的最大池化操作为结果表示提供了转换不变性。这与来自需要校准对象的完全连接层的表示形成了对比。

在我们的例子中，我们假设对象是右上的，我们只是受益于CNN由于使用的训练数据而提供的旋转公差。同样代表对规模变化的容忍度。

# 4. ENCODING REGIONS INTO SHORT VECTORS

本节描述了我们如何利用CNN卷积层的激活来推导出图像区域的表示。区域向量被聚合，以产生一个用于图像检索的过滤阶段的短签名。

**Region feature vector.**

第3节中描述的特征向量$f_Ω$是整个图像i的表示。现在，我们考虑一个矩形区域R⊆Ω=[1，W]×[1，H]，并定义区域特征向量

![image-20220714150508695](D:\文献阅读\Recent deveopments of CBIR\image\image-20220714150508695.png)

$f_{R，i}=max_{p∈R}Xi(p)$是所考虑区域上第i个通道的最大激活量。

区域R被定义在所考虑的特征映射的所有有效位置的空间Ω上（而不是在输入的图像平面上）。

大小为1的区域对应于由特定位置的单个激活组成的特征向量。

我们现在能够构建多个区域的表示，而不需要重新向CNN提供额外的输入，类似于最近的RNN变体(Ren等人，2015；吉希克，2015)，这大大降低了处理成本。

现在假设一个给定区域R与原始图像的线性映射。由于接受域较大，所提出的区域矢量捕获的图像区域矢量比反向投影的图像区域更大。类似的效果也发生在对象检测的背景下(Iandolaetal.，2014)，其中完全连接的层以滑动窗口的方式应用。

**R-MAC: regional maximum activation of convolutions.**

我们现在考虑一组不同大小的R区域。这些区域的结构与Razavian等人(2014b)提出的区域结构相似，但我们在**CNN响应图**上定义它们，而不是在原始图像上。

我们在L个不同的尺度上采样正方形区域。在最大尺度(l=1)下，确定区域大小尽可能大，即其高度和宽度都等于min(W，H)。这些区域被均匀地采样，使连续区域之间的重叠尽可能接近于40%。请注意，原始图像的长宽比对我们提取的区域的数量m有影响（只有当输入图像为正方形时才为1个区域）。在每一个其他尺度l上，我们均匀地采样宽度为2 min(W，H)/(l+1)的l×(l+m−1)区域，如图3（左）所示。

![image-20220718101221724](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718101221724.png)

图3：在3个不同的尺度上提取的样本区域(l=1...3)。我们显示了每个比例的左上角区域（灰色区域）和每个方向的邻近区域（虚线边界）。我们用一个十字来描绘所有区域的中心。

然后计算与每个区域相关的特征向量，并用l2归一化、pca白化(J‘egou&Chum，2012)和l2归一化对其进行后处理。最后将区域特征向量集合求和并进行l2归一化，将其合并为一个图像向量。这种选择使维数保持在较低的水平，这就等于特征通道的数量。然而，我们在我们的实验中表明，结果的表示，称为R-MAC，提供了比相应的MAC显著更好的性能。注意，区域向量的聚合可以看作是一个简单的核，它交叉匹配所有可能的区域，包括跨不同的规模。



1.产生regions

  首先，需要强调的一点，regions产生在feature maps上，而不是在原图上。

  在L个不同的尺度上产生正方形regions。在最大的尺度（l=1）上，region的尺寸最大。如图所示，依次为l=1,2,3。

 在某一个尺度 l 上，类似于滑动窗口，只需保证连续的两个region之间的重叠率接近于40%即可。

![image-20220718101221724](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718101221724.png)

采样时，regions的宽=高=2min（W,H）/（l+1），共采样 l*（l+1）个regions。

假设卷积网络结构中，提取特征的layer产生的feature map大小为W*H*K。以产生的region R1为例，其中的每一层d（1<=d<=K）均会产生一个大小位置与R1相同的regions。

提取每个region的feature vector，依次进行L2-normalize，PCA-whitening，L2-normalize。

  2.图像表示

   以产生的region R1为例，从d层的每个region中找到其最大的激活值 f（R1,d），以该最大值代表这个region。所以R1的feature vector可以表示为 f（R1）=[ f（R1,1），...，f（R1,d），...，f（R1,K）]，是一个1*K的向量。再次进行L2-normalize。

![image-20220718101955640](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718101955640.png)



![image-20220718101735405](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718101735405.png)

# 5. OBJECT LOCALIZATION

在本节中，我们提出了积分图像的扩展，在二维特征通道响应映射上执行近似最大池，这为我们基于cnn的方法提供了一个粗略而有效的定位。

**Approximate integral max-pooling.** 

注意到响应Xi是非负的，我们利用 generalized mean(Doll‘aretal.，2009)来近似每个特征值$f_{R，i}$，通过估计与给定区域R相关联

![image-20220718105250520](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718105250520.png)

图3（中间）显示了在几个图像区域上估计的平均近似误差|˜fR，i−fR，i|。我们报告了近似误差作为计算最大值的相应响应集的大小的函数。不同大小的响应集是使用所有可能区域的结果。指数α的高值会导致更好的近似，而应用于更多的元素会使近似不那么精确。

![image-20220718105551213](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718105551213.png)

图3：对于不同的指数α值，最大值与响应集大小的近似误差。通过评估所有可能的区域，对10个随机选择的图像进行测量。这组图像的响应以[0,151]为值。

通过近似最大值这种方式，我们现在可以使用积分图像（中提琴&琼斯，2001）近似区域特征向量fR定义在任何矩形区域r对于每个通道，我们构造的积分图像的二维张量位置p等于$X_i(p)^α，p∈R$，方程（3）的总和只是由4项的总和（中提琴&琼斯，2001）。这使我们能够有效地计算许多区域的最大池化，从而构造相应的特征向量。这与许多由完全连接的层派生的表示的区域的显式构造相反，这是禁止的，因为需要调整大小/作物和将每个区域重新提供给网络。

我们通过测量精确向量与其近似向量之间的余弦相似度来评估近似质量。这种相似性的分布如图3（右）所示，并在10幅随机选择的图像的所有可能区域上进行了测量。即使对于中等的α值，所提出的近似也是非常精确的。在我们所有的实验中，我们设置α为10。

![image-20220718110407064](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718110407064.png)

图3：精确向量$f_R$与其近似值$\widetilde{f}_R$之间的余弦相似度值的经验分布。测量值是通过在10张随机采样的图像上构造所有可能区域的精确和近似向量来收集的。

**Window detection.** 

现在让我们假设有另一个描绘单个对象的图像Q，即通过定义感兴趣对象的边界框进行裁剪。

我们将相应的MAC特征向量表示为q。定义在图像I的CNN激活X上的二维区域，使与q的相似性最大化，计算为

![image-20220718111644300](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718111644300.png)

<font color='red'>（即将所有得到的区域特征向量R-MAC和整个卷积层输出的特征向量MAC根据等式4计算相似度，从中选出相似度最高的区域特征向量，那么其对应的区域应该就能够很好地定位图像Q中感兴趣对象的边界框）</font>

区域$\widetilde{R}$最大化相似性映射到原始图像的精度$(\frac W{W_I} \frac H{H_I} )$像素，提供了在Q中描述的对象的粗略定位。

相应的相似性没有考虑到图像I的所有视觉内容，因此不受背景混乱的影响。

通过穷举搜索对最优区域的强力检测是昂贵的，因为可能存在的区域的数量在$O(W^2H^2)$中。在初步测试中，我们评估了一个基于分支和有界搜索的全局最优解决方案，如ESS(Lampertetal.，2009)。我们的表示法只是简单地推导出了必要的界。在我们的例子中，搜索的速度并没有明显加快：最大值不够明显，并且考虑了大量的区域，而维护优先级队列的开销却很高。

**AML: approximate max-pooling localization.** 

反，我们限制评估区域的数量，并用简单启发式(simple heuristics)方法在局部优化最佳区域。使用搜索步长t 来均匀采样候选区域。丢弃宽高比大于查询区域s倍的区域。以坐标下降的方式细化最佳区域的参数，允许最大3个单位的变化。细化过程要重复5次。实验表明，检测区域与最优区域的重叠程度较高。（近似实现定位的方法）

# 6. RETRIEVAL, LOCALIZATION AND RE-RANKING

**Initial retrieval**.

计算了所有数据库图像的MAC或R-MAC特征向量。同样，在查询时，我们对查询图像进行处理，并提取相应的特征向量。在过滤阶段，我们直接评估查询和所有数据库向量之间的余弦相似度。因此，我们根据MAC或R-MAC向量的相似性来获得初始排序。

**Re-ranking**

我们考虑了第二次重新排序阶段，就像在具有局部特征的空间验证(Philbin et al.， 2007)中通常执行的那样。将考虑N个top图像的short-list，并将AML(如第5节所述，即定位)应用于查询和数据库图像对上。注意，查询图像现在由MAC向量表示，因为它在AML中使用，而数据库图像由X表示。对于每一张重新排序的图像，我们获得一个由与查询图像相似度最大化的区域给出的分数。这种相似性用于对short-list的元素重新排序。此外，还提供了查询对象的粗略定位。

*Remarks:*

在滤波阶段，可以使用白化MAC（如第8节所述的白化）或R-MAC，而定位过程采用与l2归一化MAC的相似性。但是，一旦查询对象被s localized，那么查询和检测区域之间的差异将通过白化MAC或R-MAC进行相似度计算，这取决于所选择的过滤方法。这个相似度评分用于执行重新排序。仅在查询时间上构造所需的表示，并通过积分图像有效地获取

**Query expansion (QE)**. 重新排名会得到排名最靠前的位置的正图像。然后，我们收集5幅排名最高的图像，将它们与查询向量合并，计算其均值。最后，利用与该均值向量的相似性对前N幅图像重新排序。

 

# 7. IMPLEMENTATION DETAILS

我们观察到，对大于128(所有响应的0.001%)的X的响应值进行阈值设定，并将每个值映射到最接近的更小的整数(floor操作)，会导致较小的损失。这样就可以允许带有查找表的α-th power计算，并加速积分图像的构造。此外，我们通过对同一张α-th power查找表进行二分搜索来近似式(3)的α次方根。这个过程使得最优窗口搜索更加高效。

以X表示的响应图是稀疏的(Agrawal et al.，2014)。特别是，利用Krizhevsky等人(2012)在Oxford Buildings数据集(Philbin et al.，2007)上训练的网络将导致81%的响应值为零，便于存储。我们进一步通过将响应一致量化为8个值来减少内存需求。这将导致更多的元素映射到相同的值。因此，我们使用delta编码来存储非零值的位置，并且每个非零元素只使用1字节。注意，在相同的网络中，分辨率为1024×768的图像对应大小为30×22的特征通道响应图。最后，一个图像需要大约32 kB的内存。在重新排序时，我们每次构造一个积分图像，并对其元素使用双精度(8字节)



# 8. EXPERIMENTS

本节介绍了我们的图像检索紧凑表示的结果，评估了定位AML的精度，并最后将其用于检索重新排序。

**Experimental setup**. 

我们在分别由5063幅图像和6412幅图像组成的Oxford Buildings数据集(Philbin et al.， 2007)和Paris数据集(Philbin et al.， 2008)上评估了所提出的方法。我们将这些数据集称为Oxford5k和Paris6k。我们还使用了100k的Flickr图片(Philbin et al.，2007)分别组成Oxford105k和Paris106k。该来自Flickr图片 (Je ́gou et al., 2010) 的100k干扰集图像被额外使用以实现更大的数据规模。检索性能以mean Average Precision(mAP)来衡量。我们遵循标准协议并使用在查询图像上定义的边界框。这些边界框也被用来评估定位精度。在Oxford5k上测试时，主成分分析是在Paris6k上学习的，反之亦然。为了公平起见，我们只直接将我们的结果与以前没有在测试集上执行学习的方法进行比较。

我们工作的重点不是训练CNN，而是从卷积层中提取视觉描述符。我们使用了文献中广泛使用的网络:Krizhevsky等人(2012)的AlexNet和Simonyan & Zisserman(2014)的very deep network (VGG16)。我们之所以选择VGG16而不是VGG19，是因为我们发现后者在特征提取成本较高的情况下并不总是能够获得更好的性能。我们的表征是从最后一个池化层提取的，其中AlexNet有256个特征通道，VGG16有512个特性通道。MatConvNet (Vedaldi & Lenc, 2014)用于提取特征。

**Localization accuracy**.  

为了评估AML的准确性，我们使用成对的Oxford5k查询图像及其对应的正图像。我们首先执行穷举搜索来检测全局最优窗口。然后，我们应用我们的加速检测器，评估较少的区域，并最终细化最好的一个区域。在这两种情况下，每个窗口计算都使用近似的max-pooling。我们报告了与最优窗口的交并集(IoU)，以及与穷举情况相比评估的窗口数量的百分比（即优化方法查询的窗口数量/穷举方法查询窗口数量）。结果如表1(左)所示。我们提供了一个大的加速，同时保持高重叠的最佳检测。回想一下，我们的目的是应用这个检测器来快速重新排序。测量IoU为定位精度提供了证据，但是我们观察到它并不直接影响检索性能。我们最终为重新排序设置s = 1.1和t = 3。

![image-20220718144202238](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718144202238.png)

为了评估与ground truth标注相关的定位精度，我们交叉匹配每个建筑存在的5张查询图像。其中一个用作查询(裁剪边框)，而对于另一个，我们将检测到的区域与ground-truth标注进行比较。在Oxford5k (Paris6k)数据集上，穷举评估获得的IoU值为52.6%(52.9%)，加速方法获得的IoU值为51.3%(51.4%)。精度损失是有限的，而定位大约是180倍快。AML提供了一个低计算代价的粗略定位。当用单线程实现对1000张图片重新排序时，这样的设置导致使用AlexNet的平均重新排序查询时间为2.9秒。

**Retrieval and re-ranking**. 

我们使用MAC和R-MAC紧凑表征来评估检索性能。对MAC向量分别进行l2-归一化、PCA-白化和l2-归一化，对R-MAC的相应处理则如第4节所述。表1(右)给出了Oxford5k上的结果。我们评估不同的输入图像分辨率，观察原始图像大小为1024时提供更高的性能。请注意，MAC与Azizpour等人(2014)提出的MAC类似，但是他们的过程仍然受到标准输入大小和高宽比的限制。由于两个特征向量具有完全相同的维数，该算法在不增加额外代价的情况下，大大提高了算法的性能。将不同尺度的区域聚合在一起，即L = 3意味着将尺度l = 1、l = 2和l = 3的区域组合在一起。我们在下面设L = 3。为了分解R-MAC的组成部分，我们通过只聚集l = 3的区域来构造R-MAC。使用VGG16在Oxford5k数据集上实现的mAP等于63.0。聚合l = 2和l = 3两个区域将mAP提高到65.4。最后，添加l = 1(原来的R-MAC)后执行66.9的mAP效果(见表1)。在Oxford105k上的过滤时间平均为12 ms。

接下来我们使用AML对图像进行重新排序，在Oxford105k上对多达1000张图像进行重新排序的性能评估。性能得到了持续的提高，如图4所示。R-MAC带来了更大的好处，VGG16表现比AlexNet更好。如第6节所述，查询扩展（QE）方法以较低的额外成本提高了性能，因为只对重新排序的short-list重新计算相似度。最后，我们使用1M张干扰物图像进行了大规模实验，结果如图4所示。AML将性能提高了13%。

![image-20220718145236242](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718145236242.png)

图5展示了使用MAC排序和使用AML重新排序的例子。回想一下，我们只提供了一个粗略的目标定位，因为我们的主要目标是获得改进的图像相似度。此外，所提供的定位对于重新排序来说足够精确。

![image-20220718145436769](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718145436769.png)

**Comparison to the state of the art**. 

我们将提出的方法与最先进的紧凑表征和基于局部特征的方法进行比较，这些方法执行精确的描述符匹配、重新排序或查询扩展。结果如表2所示。使用AlexNex和VGG16分别为R-MAC生成256维和512维的向量。对于紧凑的表征，我们的小尺寸R-MAC优于所有其他方法。在Paris数据集上的更好性能是从预先训练网络的性质继承的;使用VGG的基准MAC在Oxford5k上达到55.2的mAP，在Paris6k上达到74.7的mAP。

与以往基于CNN层的描述方案不同，我们的方法在几何匹配和查询扩展方面可与基于局部特征的最佳方法竞争。我们的AML甚至可以超过它们:虽然我们在Oxford数据集上的成绩较低，但我们在Paris数据集上取得了最好的成绩，而且据我们所知，在这个基准测试中，我们的成绩超过了所有已发布的结果。Paris6k数据集上最好的成绩是由Arandjelovic和Zisserman(2012)(91.0)和Zhong等人(2015)(91.5)报告的。这些都是通过学习Paris6k本身的码本和执行索引数据集的预处理来实现的。

![image-20220718150110460](D:\文献阅读\Recent deveopments of CBIR\image\image-20220718150110460.png)

**Discussion about other CNN-based approaches**. 

Razavian等人(2014b)提出执行区域交叉匹配（cross-matching），并累积每个查询区域的最大相似度。我们利用R-MAC中区域向量的集合来评估交叉匹配过程;我们简单地跳过最后的聚合过程，单独保留区域向量。交叉匹配在Oxford5k中作为过滤阶段能达到75.2% mAP，而在此之上使用AML重新排列作为补充，能将性能提高到78.1%。然而，交叉匹配有两个缺点。首先，需要将区域向量单独存储，增加|R|倍数的内存需要，其中|R|为提取区域的数量。其次，复杂度代价在索引图像的数量上是线性的，并且相当高，因为它需要计算每个图像的|R|2(例如1024 (Razavian et al.， 2014b))个内积。Razavian等人(2014b)的工作通过扩大提供的查询边框，遵循了一种非标准的评估协议。另外，他们向CNN提供了32幅576×576分辨率的图像，特征提取的成本非常高。Xie等人(2015)最近的工作与他们的工作非常相似，在检索和分类方面都有应用。

Babenko和Lempitsky(2015)表明，在最终的图像向量进行了PCA白化后时，卷积层激活的全局sum-pooling效果优于max-pooling。如果不使用白化，那么后者更好。在目标定位中，我们利用AML在查询时对大量候选区域进行了有效的评估。对每个候选区域向量进行白化，会显著增加白化的代价，所以在该任务重是禁止的。为了我们提出的R-MAC和AML以及测试性能，我们将max-pooling切换到sum-pooling。注意，sum-pooling是我们的integral max-pooling的参数α=1的特殊情况。在Paris106k上切换到sum-pooling使R-MAC得到69.8的mAP, R-MAC +AML +QE则能得到76.9的mAP。这些分数可以直接与表2中的分数进行比较，并表明我们的选择在所有情况下都是更好的。