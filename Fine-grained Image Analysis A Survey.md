# Fine-Grained Image Analysis with Deep Learning: A Survey

细粒度图像分析（FGIA）是计算机视觉和模式识别中一个长期存在的基本问题，是一系列现实应用的基础。

FGIA的任务是分析从属类别的视觉对象，如鸟类种类或汽车模型。细粒度图像分析所固有的小的类间变化和大的类内变化使其成为一个具有挑战性的问题。

利用深度学习的进步，近年来，我们见证了深度学习驱动的FGIA的显著进展。

在本文中，我们对这些进展进行了系统的调查，我们试图通过巩固两个基本的细粒度研究领域——细粒度图像识别和细粒度图像检索来重新定义和拓宽FGIA的领域。

此外，我们还回顾了FGIA的其他关键问题，如公开可用的基准数据集和相关的特定领域的应用程序。最后，我们强调了一些需要社区进一步探索的研究方向和开放的问题

# 1 INTRODUCTION

人类的视觉系统天生就具有细粒度的图像推理能力——我们不仅能够区分狗和鸟，而且还能知道西伯利亚哈士奇和阿拉斯加雪橇犬之间的区别（见图1）。细粒度图像分析（FGIA）被引入学术界也是为了同样的目的，即教机器以细粒度的方式“看到”。FGIA方法在工业和研究中都有广泛的应用，例如自动生物多样性监测[1]，[2]，[3]，智能零售[4]，[5]，[6]，和智能交通[7]，[8]，，并在保护[9]和商业[10]等领域产生了积极的影响。 

计算机视觉中的FGIA的目标是检索和识别属于一个超类别的多个下属类别（即元类别或基本级别类别）的图像，如不同种类的动物/植物、不同型号的汽车、不同种类的零售产品等。

因此，关键的挑战在于理解细粒度的视觉差异，这些差异足以区分在整体外观上高度相似，但在细粒度特征上不同的物体。[11]，[12]，[13]自近20年前成立以来已经取得了巨大的进步。

特别是深度学习[14]已经成为一种强大的鉴别特征学习方法，并在FGIA领域取得了显著的突破。支持深度学习的FGIA极大地推进了这些方法在不同应用场景[5]、[7]、[8]、[9]中的实际部署。

近年来，计算机视觉和机器学习研究界都对FGIA产生了极大的兴趣。粗略的统计数据表明，每年在每个高级视觉和机器学习会议上都平均发表了10篇关于基于深度学习的FGIA的>会议论文。还有一些特殊的问题涉及FGIA [15]，[16]，[17]，[18]，[19]。此外，FGIA上一些有影响力的比赛经常在在线平台上举行。代表包括一系列自然主义竞赛（针对大量自然物种）[20]、自然保护渔业监测（鱼类物种分类）[21]、座头鲸鉴定（鲸鱼身份分类）[22]等。每场比赛都吸引了来自世界各地的数百名选手，有些甚至超过2000支队伍。针对FGIA主题的特定教程和研讨会也在顶级国际会议上举行，如[23]，[24]。

尽管有如此突出的兴趣，深度学习的研究仍然支离破碎。

因此，本调查的目的是

(i)提供FGIA近期成果的全面调查，特别是深度学习技术带来的成果，更重要的是

（ii）通过整合FGIA不同方面的研究，提出一个统一的研究战线。我们的方法与现有的调查[25]，[26]有显著的不同，后者只关注细粒度识别/分类的问题，我们认为这只是构成了更大的FGIA研究的一部分。特别是，我们试图通过重新定义和拓宽细粒度图像分析领域，突出细粒度识别之间的协同作用，和并行但互补的任务，这也是FGIA的一个组成部分。

我们的调查采用了一个独特的基于深度学习的视角，以广泛、系统和全面的方式回顾了FGIA的最新进展。

我们的主要贡献总结如下：

- 我们拓宽了FGIA的领域，通过提供一个统一的景观，促进细粒度图像分析中相关问题之间的协同作用。
- 我们提供了基于深度学习的FGIA技术的全面回顾，包括普遍接受的问题定义、基准数据集、不同家族的FGIA方法，以及覆盖特定领域的FGIA应用程序。特别是，我们以分类的方式组织这些方法（参见图2），为读者提供该领域最先进技术的快速快照。

- 我们在几个公开的数据集上整合了现有方法的性能，并提供讨论和见解，为未来的研究提供信息。

- 最后，我们将讨论现有的挑战和开放的问题，并确定新的趋势和未来的方向，为社区解决这些问题提供一个合理的路线图。
- 最后，为了不断跟踪这一快速发展领域的最新发展，我们提供了一个网页，根据我们基于问题的分类对解决FGIA问题的论文进行分类： http://www.weixiushen.com/project/Awesome_FGIA/Awsosk_FGIA.html。

![image-20220919161656930](D:\文献阅读\fine-grained\image\image-20220919161656930.png)

# 2 RECOGNITION VS. RETRIEVAL

以前对FGIA的调查，如[25]，[26]，主要集中于细粒度识别，因此并没有暴露FGIA问题的所有方面。

在本调查中，我们首次涵盖了细粒度图像分析的两个基本领域（即识别和检索），以全面回顾基于深度学习的FGIA技术的最新进展。在图2中，我们提供了一个反映当前FGIA景观的新分类法

**细粒度识别**：我们将不同家族的细粒度识别方法组织成三种范式，即

1)定位分类子网络识别，

2)端到端特征编码识别，

3)外部信息识别。

细粒度识别是FGIA中研究最多的领域，因为识别是大多数视觉系统的基本能力，因此值得长期持续研究。

**细粒度检索**：基于查询图像的类型，我们将细粒度检索方法分为两组，即

1)基于内容的细粒度图像检索和

2)基于草图的细粒度图像检索。

与细粒度识别相比，细粒度检索是近年来FGIA的一个新兴领域，越来越受到学术界和工业界的关注

**识别和检索的差异**:细粒度识别和检索的目的都是识别不同细粒度对象之间的区别性的，但这是不同细粒度对象之间的细微差别。然而，细粒度识别是一项具有固定数量的从属类别的封闭世界任务。相比之下，细粒度检索将问题扩展到具有无限子类别的开放世界设置。此外，细粒度检索还旨在对所有实例进行排序，以便描述感兴趣的概念（例如，相同的子类别标签）的图像根据查询中的细粒度细节排名最高。

**识别和检索协同作用**：在细粒度识别和检索方面的进步有共同之处，并且可以相互受益。细粒度的识别和检索共享了许多常见的技术，如深度度量学习方法[27]、[28]、多模态匹配方法[29]、[30]，以及选择有用的深度描述符[31]、[32]的基本思想等。第7节详细讨论。此外，在现实应用中，细粒度识别和检索也相互补充，例如，检索技术能够通过利用从细粒度识别模型[5]，[33]中学习到的表示来支持新的子类别识别。

# 3 BACKGROUND: PROBLEM AND CHALLENGES

细粒度图像分析（FGIA）侧重于处理属于同一元类别的多个从属类别的对象（如不同种类的鸟类或不同的汽车模型），通常涉及两个中心任务：细粒度图像识别和细粒度图像检索。如图3所示，细粒度分析是在基本级类别分析（即通用图像分析）和实例级分析（如个体识别）之间的连续体。

![image-20220919170253807](D:\文献阅读\image\image-20220919170253807.png)

具体来说，FGIA与通用图像分析的区别在于，在通用图像分析中，目标对象属于粗粒度元类别（即基本级别类别），因此在视觉上完全不同（例如，确定图像是否包含鸟、水果还是狗）。**然而，在FGIA中，由于对象通常来自同一元类别的子类别，因此问题的细粒度性质导致它们在视觉上是相似的**。作为细粒度识别的一个例子，在图1中，任务是对不同品种的狗进行分类。为了准确的图像识别，有必要捕捉细微的视觉差异（例如，有区别特征，如耳朵、鼻子或尾巴）。对于其他FGIA任务（例如，检索），也需要描述如此的特征。此外，如前所述，由于问题的细粒度性质具有挑战性，由高度相似的子类别引起的类间变化，以及姿态、尺度和旋转的大变化（见图4）。因此，它与一般的图像分析（即，小的类内变化和大的类间变化）相反，并使FGIA成为一个独特的和具有挑战性的问题。

虽然实例级分析通常针对对象的特定实例，而不仅仅是对象类别或对象子类别，但如果我们向下移动粒度谱，在极端情况下，个体识别(例如，人脸识别)可以被视为细粒度识别的特殊实例，其中粒度位于个体身份级别。

例如，人/车辆再识别[7]，[34]可以被认为是一个细粒度的任务，其目的是确定是否为同一特定的人/车辆拍摄了两张图像。在实际应用中，这些工作利用与FGIA相关的方法解决了相应的领域特定问题，如捕获对象（[8]、人脸、人、车辆）的识别部分，发现从粗到细的结构信息[37]，开发基于属性的模型[38]、[39]等。对这些实例级问题的研究也非常活跃。然而，由于这些问题不在经典FGIA的范围内（见图3），有关更多信息，我们请读者调查这些特定主题的论文，如[7]，[34]，[40]。下面，我们首先阐述我们对经典FGIA的定义。

**公式**：在一般图像识别中，我们给出一个训练数据集$D=\{(x^{(n)}，y^{(n)})|i = 1，...，N\}$，包含多个图像和相关的类标签（即x和y），其中$y∈[1，...，C]$。每个实例（x、y）根据pr (x、y）的分布，都属于图像空间和标签空间（即x和y）的联合空间

![image-20220919171742869](D:\文献阅读\image\image-20220919171742869.png)

特别地，标签空间Y是与C类别对应的所有C子空间的并集空间，即$Y = Y_1∪Y_2∪···∪Y_c∪···∪Y_C$。

然后，我们就可以训练一个预测/识别深度网络f（x；θ）由θ参数化，通过最小化预期风险进行通用图像识别

![image-20220919172132011](D:\文献阅读\image\image-20220919172132011.png)

其中，L（·，·）是一个损失函数，它度量真实标签与f（·；θ）预测的标签之间的匹配。而如前所述，细粒度识别的目的是从某个元类别中准确地分类不同从属类别的实例，即：

![image-20220919172222021](D:\文献阅读\image\image-20220919172222021.png)

其中，y'表示细粒度的标签，Yc表示类c的标签空间为元类别。因此，细粒度识别的优化目标是作为

![image-20220919172323083](D:\文献阅读\image\image-20220919172323083.png)

与细粒度识别相比，除了细粒度检索正确外，还必须对所有实例进行排序，以便在检索任务查询中根据细粒度细节对属于同一子类别的图像排名最高。

给定一个输入查询$x^q$，细粒度检索系统的目标是根据它们与查询的细粒度相关性，对检索集$Ω=\{x^{(i)}\}^M_{i=1}$（其标签y'∈Yc）中的所有实例进行排序。让$S_Ω = \{s^{(i)}\}^M_{i=1}$表示$x^q$和每个$x^(i)$之间的相似性，通过应用于相应的细粒度表示的预定义度量来测量，即$h（x^q；δ）$和$h(x^{(i)};δ)$。这里，δ表示检索模型h的参数。对于那些标签与$x^q$的细粒度类别一致的实例，我们将它们形成一个正集$P_q$，并得到相应的$S_P$。然后，可以通过最大化基于排名的分数来对检索模型h（·；δ）进行训练

![image-20220919173123790](D:\文献阅读\image\image-20220919173123790.png)

所有的查询图像，其中$R(i，S_P)$和$R(i，S_Ω)$分别表示实例i在$P_q$和Ω中的的排名。

# 4 BENCHMARK DATASETS

近年来，视觉社区发布了许多细粒度的基准数据集，涵盖了不同的领域，例如，鸟类[1]、[13]、[41],狗[27],[42],[43]汽车,飞机[44],
花[45]，蔬菜[46]，水果[46]，食物[47]，时尚[6]，[33]，[38]，零售产品[5]，[48]等。此外，值得注意的是，即使是最流行的大规模图像分类数据集，即ImageNet [49]，也包含了覆盖许多狗和鸟子类别的细粒度类。

在图5中可以找到来自其中一些细粒度基准数据集的代表性图像。在表1中，我们总结了最常用的图像数据集，并指出了它们的元类别、图像的数量、类别的数量、它们的主要任务，以及额外的可用监督，例如，边界框、部分注释、层次标签、属性标签和文本描述(cf。图6）。

![image-20220919185134271](D:\文献阅读\image\image-20220919185134271.png)

![image-20220919185150251](D:\文献阅读\image\image-20220919185150251.png)

这些数据集是该领域取得重大进展的最重要因素之一，不仅是衡量和比较竞争方法性能的共同点，而且也推动该领域向日益复杂、实际和具有挑战性的问题发展。

细粒度鸟类分类数据集CUB-200- 2011 [13]是最流行的细粒度数据集之一。大多数的FGIA方法都选择它来与最先进的方法进行比较。此外，在CUB200-2011上对高级任务的持续贡献，例如，收集细粒度图像的文本描述用于多模态分析，cf[58]，[59]和第5.3.2节。

近年来，人们提出了更具挑战性和实用的细粒度数据集，例如，iNat2017包含不同种类的植物和动物[2]，以及用于零售产品[5]的RPC。这些数据集的新特性包括：它们是大规模的，具有层次结构，表现出一个域间隙，并形成一个长尾分布。这些挑战说明了FGIA在现实世界中的实际要求，并激发了新的有趣的研究挑战。第8节）。

除此之外，我们还构建了一系列基于细粒度草图的图像检索数据集，如QMUL-Shoe [52]、QMULChair [52]、QMUL-potys[54]、SBIR2014 [51]、SBIR2017 [55]、素描[53]、QMUL-Shoe-V2 [56]，以进一步推进细粒度检索的发展，cf。第6.2节。此外，我们还构建了一些新的数据集和基准测试，如FG-Xmedia [57]，将细粒度图像检索扩展到细粒度跨媒体检索

# 5 FINE-GRAINED IMAGE RECOGNITION

细粒度图像识别是近十年来FGIA最活跃的研究领域。细粒度识别的目的是区分属于同一基本类别的许多视觉上相似的从属类别，如动物物种[2]、汽车[43]、水果[46]、飞机模型[44]等的精细区分。它经常被应用于现实世界的任务中，如生态系统保护（识别生物物种）[9]、智能零售系统[5]、[10]等。由于区分区域定位和细粒度特征学习的挑战，识别细粒度类别是困难的。研究人员已经试图从不同的角度来应对这些挑战。在本节中，我们将回顾自深度学习出现以来主要的细粒度识别方法

一般来说，现有的细粒度识别方法可以组织成以下三种主要范式：

- 定位分类子网络识别；
- 端到端特征编码识别；
- 利用外部信息识别。

其中，前两种范例只利用与细粒度图像相关联的监督来限制自身，如图像标签、边界框、部件注释等。为了进一步解决模糊的细粒度问题，有大量的工作使用额外的信息，如图像在何时拍摄[60]，[61]，web图像[62]，[63]，或文本描述[58]，[59]。为了直观地展示这些具有代表性的基于深度学习的细粒度识别方法，我们在图7中通过将它们组织成上述三个范式来进行时间顺序概述。

![image-20220919191223222](D:\文献阅读\image\image-20220919191223222.png)

对于性能评估，当测试集是平衡的时（即，每个类都有一个类似的数字测试示例），细粒度识别中最常用的度量是数据集所有从属类别的分类精度。将其定义为

![image-20220919191442917](D:\文献阅读\image\image-20220919191442917.png)

$|I_{total}|$表示测试集中所有子类别的图像数量，$|I_{correct}|$表示模型正确分类的图像数量。

## 5.1通过定位-分类子网进行的识别

研究人员试图创建模型来捕获细粒度对象的区别语义部分，然后构建与这些部分相对应的中层表示，用于最终的分类，cf图8. 更具体地说，设计了定位关键部分，然后得到相应的部分级（局部）特征向量。这通常与对象级(全局)图像特性结合使用，以表示细粒度的对象。

![image-20220919191706771](D:\文献阅读\image\image-20220919191706771.png)

接下来是一个执行识别的分类子网络。这两个协作子网的框架形成了第一个范式，即使用定位-分类子网的细粒度识别。这些模型的动机是首先找到相应的部分，然后比较它们的外观。具体地说，我们希望捕获在细粒度类别中共享的语义部分（例如，头部和躯干），并发现这些部分表示之间的细微差异。

该范例中现有的方法可以分为四种主要类型： 1)使用检测或分割技术，2)使用深度过滤器，3)利用注意机制，以及4)其他方法。

### 5.1.1采用检测或分割技术

采用检测或分割技术[116]、[117]、[118]可以直接定位与细粒度物体部分对应的关键图像区域，如鸟头、鸟尾、汽车灯、狗耳、狗的躯干等。多亏了定位的信息，，即部分级边界框或分割掩码，该模型可以获得更有鉴别性的中层（部分级）表示w.r.t.这些部分。从而可以进一步提高分类子网络的学习能力，从而显著提高最终的识别精度.

在这个范例中的早期工作使用了额外的密集部分注释(又名关键点标注，cf图6左边)，以定位对象的语义关键部分。

例如，Branson等人[64]提出使用检测到的部分关键点组来计算多个扭曲的图像区域，并通过姿态归一化进一步得到相应的部分级特征。

在同一时期，Zhang等人[65]首先基于地面真实部分标注生成部分级边界框，然后训练R-CNN [118]模型进行部分检测。

Di等人[67]进一步提出了一种 Valve Linkage Function，该函数不仅连接了所有子网，而且根据*part alignment*结果细化了定位。

为了集成语义部分检测和抽象，SPDA-CNN [69]设计了一种自上而下的方法，通过继承先验的几何约束来生成*part-level*建议，然后使用更快的R-CNN [116]返回部分定位预测。

其他的方法则利用了分割信息。PS-CNN [68]和Mask-CNN [31]采用分割模型得到部位/对象掩码，以帮助部位/对象定位。与检测技术相比，分割可以得到更精确的部分定位[31]，因为分割侧重于更精细的像素级目标，而不仅仅是粗糙的边界框。

____

然而，使用传统的检测器或分割模型需要密集的部分注释来进行训练，这是劳动密集型的，并将限制现实世界的细粒度应用程序的可伸缩性和实用性。因此，我们希望仅使用图像级标签[70]、[72]、[73]、[74]、[75]就可以准确地定位细粒度的部位。这些方法被称为“弱监督”，因为它们只使用图像级标签。值得注意的是，自2016年以来，在这种弱监督设置中开发细粒度方法有一个明显的趋势，而不是强监督设置（即使用部分注释和边界框），cf表2。

在基于弱监督定位的分类设置中，识别方法总是依赖于无监督方法来获得与对象部分相对应的语义群。

具体来说，Zhang等人的[70]采用了空间金字塔策略[119]从对象提案生成部分建议。然后，通过使用聚类方法，他们生成部分建议原型聚类，并进一步选择有用的聚类来获得有区别的部分级特征。

基于共分割[120]的方法也常用于这种弱监督的情况下。一种方法是在不受监督的情况下使用共分割来获得对象掩模，然后执行启发式策略，如部分约束[72]或部分对齐[66]，以定位细粒度的部分。



___

值得注意的是，以往的大部分工作都忽略了区分部分级特征之间的内部语义相关性。具体地说，上述方法独立地挑选出区分区域并直接利用其特征，而忽略了对象的特征相互语义相关，区域组更有区分性的事实。

因此，最近，一些方法试图联合学习部分级特征之间的相互依赖关系，以获得更通用、更强大的细粒度图像表示。

通过执行不同的特征融合策略(如LSTMs[71]，[73]，graphs[74]，或知识蒸馏[75])，这些联合部分特征学习方法获得了显著更高的识别率
优于以前的独立部分特征学习方法。

### 5.1.2利用深度过滤器

在深度卷积神经网络（CNNs）中，深度滤波器（即CNN滤波器）指的是卷积层[14]的学习权值。

来自这些深度过滤器的响应/激活可以被看作是本地化的描述符。深度描述符具有以下属性[121]：

1)局部性：它们描述并对应于局部图像区域关于整个输入图像

2)空间性：它们也能够编码空间信息。随着研究开始探索CNN在计算机视觉中的应用，研究人员逐渐发现中间CNN输出（例如，局部深度描述符）可以与普通对象[122]的语义部分相连。

因此，细粒度社区尝试将这些滤波器输出作为部分检测器[76]、[77]、[78]、[79]、[80]、[81]、[82]，从而依赖它们来进行定位-分类细粒度识别。这里的一个主要优点是，这不需要任何部分级别的注释。

Xiao等人[76]对这些深度滤波器进行光谱聚类[123]，形成组，然后使用滤波器组作为部分检测器。

类似地，NAC [78]利用CNN的通道作为部位探测器。

Liu等人[77]开发了一种跨层池化方法，通过使用来自两个连续卷积层的激活作为指导，聚合基于部位的深度描述符。

提出PDFS [79]选择部分对应的深度滤波器，然后迭代更新学习到的“检测器”，从而发现鉴别的和一致的基于部分的图像区域。

对于上述方法，在使用预先训练的分类cnn中的深度滤波器获得检测到的部分后，他们通常训练离线分类器，如支持向量机或决策树[123]，使用基于部分的特征向量进行最终的识别任务。

_____

为了便于部分检测和基于部分的分类的学习，我们开发了统一的端到端训练的细粒度模型[80]、[81]、[82]。因此，观察到显著的识别改进，cf。表2. 

Wang等人[80]使用了一个额外的可学习的1×1卷积滤波器作为一个小补丁（即部分）检测器。接下来是一个全局最大池，以保持最高的激活w.r.t.为最终的分类所准备的过滤器。

之后，基于类响应映射图[124]，S3N [81]利用类峰值响应，即局部最大值，作为部分局部定位的基础。与[71]，[73]，[74]类似，S3N也以相互部分学习的方式考虑部分相关性。

### *5.1.3 Leveraging Attention Mechanisms*

尽管以前的定位分类细粒度方法显示出了很强的分类性能，但它们的一个主要缺点是它们需要对对象部分进行有意义的定义。

**然而，在许多应用程序中，可能很难表示或甚至定义某些对象类的公共部分，例如，非结构化对象，如食物盘[47]或具有重复部分[45]的花。**

与这些定位分类方法相比，寻找部分的一个更自然的解决方案是利用注意机制[125]作为子模块。

这使得cnn能够为细粒度对象的松散定义区域，因此成为一个很有前途的方向。

众所周知，注意在人类感知[125]，[126]中起着重要的作用。人类利用一系列的部分一瞥，选择性地关注物体或场景的显著部分，以更好地捕捉视觉结构[127]。

.受此启发，Fu等人和Zheng等人[83]，[84]是第一个结合注意处理来提高cnn的细粒度识别精度

具体来说，RA-CNN [83]使用一个循环的视觉注意模型来选择一系列的注意区域（对应于物体的“部分”1）。RA-CNN以之前的预测为参考，以粗到细的方式迭代生成区域注意图。

MA-CNN [84]配备了一个多注意的CNN，可以并行返回多个区域的注意。

随后，Peng等人[85]和Zheng等人[88]提出了多层次的注意模型来获取**多层次的注意信息**（即对象水平和部分水平）。

He[128]等人应用多层关注，通过n路径端到端识别定位网络同时定位每个图像的多个识别区域，该网络同时定位识别区域并编码其特征。

与上述的单层次的注意方法相比，这种多层次的注意可以产生多样化和互补的信息。

Sun等人的[27]结合了通道注意[129]和度量学习[130]，以加强不同注意区域之间的相关性。

Zheng等人[87]开发了一个三线性注意采样网络，从数百个部分提案中学习细粒度的细节，并有效地将学习到的特征提取成一个CNN。

最近，Ji等人[89]提出了一种基于注意的卷积二元神经树，它将注意机制与树状结构结合起来，以促进从粗到细的层次细粒度特征学习。

虽然注意机制在细粒度识别中取得了较强的准确性，但在小规模数据的情况下，它倾向于过拟合。

### *5.1.4 Other Methods*

在定位-分类范式中的许多其他方法也被提出用于细粒度识别。

Spatial Transformer Networks（STN）[90]最初被引入，以一种端到端可学习的方式显式地执行空间转换。它们还可以并行配备多个变压器，以进行细粒度识别。STN中的每个变压器都可以对应于一个具有空间转换能力的部位检测器。

后来，Wang等人[91]开发了一个具有几何约束的三联体补丁作为模板，自动挖掘可识别的三联体，然后用挖掘的三联体生成中层表示进行分类。

此外，其他方法通过引入反馈机制获得了更好的精度。

具体来说，NTS-Net [92]采用multi-agent cooperative learning scheme (多智能体协作学习方案)来解决细粒度识别的核心问题，即准确识别图像中的信息区域。

M2DRL[93]，[131]是第一个在对象和部分级别上利用深度强化学习[132]，利用其定制的奖励函数捕获多粒度的鉴别定位和多尺度表示。

受自然语言处理[133]中的低秩机制的启发，Wang等人[94]提出了DF-GMM框架来缓解高级特征图中的区域扩散问题。DF-GMM首先通过构建低秩基，从高级特征图中选择有区别的区域，然后利用低秩基的空间信息重建低秩特征图。部位相关性也可以通过重组处理来建模，从而提高了准确性。

## **5.2 Recognition by End-to-End Feature Encoding**

细粒度识别的第二种学习范式是端到端特征编码。与其他视觉任务一样，特征学习在细粒度识别中也起着重要作用。由于子类别之间的差异通常是非常微妙和局部的，仅使用完全连接的层捕获全局语义信息限制了细粒度模型的表示能力，从而限制了最终识别性能的进一步改进。

因此，人们开发了一种学习统一的、有区别的图像表示，通过以下方式建模细粒度类别之间的细微差异： 

1)通过高阶特征交互，

2)通过设计新的损失函数，

3)通过其他方法。

### *5.2.1 Performing High-Order Feature Interactions*

特征学习在几乎所有的视觉任务，如检索、检测、跟踪等中都起着至关重要的作用。深度卷积网络的成功主要是由于学习到的鉴别深度特征。在深度学习的初始时代，全连接层的特征（即激活）通常被用作图像表示。后来，发现更深的卷积层的特征图包含中高级信息，如对象部分或完整对象[134]，这导致了卷积特征/描述符[77]、[135]的广泛使用。cf图9。

![image-20220920111810153](D:\文献阅读\image\image-20220920111810153.png)

此外，与全连通输出[135]、[136]、[137]相比，对这些局部卷积描述符应用编码技术已经有了显著的改进。在某种程度上，这些编码技术上的改进来自于在最终特征的*higher-order* statistics 编码。特别是对于细粒度识别，当SIFT特征的Fisher向量编码在几个细粒度任务[138]中优于微调的AlexNet时，对高阶统计量的端到端建模就变得明显。

基于协方差矩阵的表示[139]，[140]是一种具有代表性的高阶（即二阶）特征交互技术，已应用于计算机视觉和机器学习。

让$V_{d×n}=[v_1，v_2，…，v_n]$表示一个数据矩阵，其中每一列包含一个$v_i∈R^d$的局部描述符，从图像中提取。

对应的d×d上的样本协方差矩阵记为$Σ=\bar{V}\bar{V}^T>$（或简称$Σ=VV^T$），其中$\bar{V}$表示为中心化的V。最初，这个协方差矩阵被提出作为一个区域描述符，例如，描述图像补丁中像素颜色强度的协方差。近年来，它已被用作一种很有前途的二阶合并图像表示的视觉识别。

通过将基于协方差矩阵的表示与深度描述子相结合，在过去的几年中，一系列的方法在细粒度识别方面显示出了很好的精度。

其中最具代表性的方法是双线性CNNs [95]，[141]，它将图像表示为两个深度CNNs 特征的经过池化后的外积，从而编码卷积激活的二阶统计，从而明显改进细粒度识别。

当两个cnn被设置为相同时，这个外部乘积本质上导致了一个协方差矩阵（以$VV^T$的形式）。然而，外部乘积操作产生了极高的维特征，即双线性合并特征被重塑为一个向量$z = vec(VV^T)∈R^{d^2}$。这导致了深度网络分类模块中参数数量的大幅增加，从而导致过拟合，使其不适合于现实的应用，特别是大规模的应用。

为了解决这个问题，Gao等人[96]应用张量草图[142]来近似原始双线性池化操作的二阶统计量，并减少特征维数。

Kong等人[98]对协方差矩阵采用低秩近似，进一步学习了低秩双线性分类器。所得到的分类器可以在不明确计算双线性特征矩阵的情况下进行评估，从而大大减少了参数的大小。

i等人的[143]还通过使用低秩约束进行二次变换来建模两两的特征交互作用。

Yu等人[103]在双线性池化之前使用了降维投影来缓解维数爆炸。

Zheng等人[105]将双线性池应用于特征通道组，其中双线性变换通过计算每个组内的成对交互作用来表示。这也导致了大量的节省在计算成本。

除了这些方法之外，一些方法试图捕获更高阶（超过二阶）的特征交互，以产生更强、更有区别的特征表示。

Cui等人[97]引入了一种核池化方法，通过紧凑的特征映射捕获任意有序和非线性的特征。

Cai等人[100]提出了一种基于多项式核的预测器来建模跨多层卷积激活的高阶统计量，用于建模部分交互。随后，开发了DeepKSPD [102]，以端到端可训练的方式联合学习深度局部描述子和基于核矩阵的协方差表示。

由于l2特征归一化可以抑制高响应的常见模式，从而增强那些具有鉴别性的原生特征(即视觉突发问题[104]，[144])，上述基于双线性池的方法通常执行元素平方根归一化，然后在协方差矩阵上执行l2归一化，以提高性能。

然而，仅仅采用l2-归一化会导致高阶信息不稳定，也会导致收敛速度较慢。为此，许多方法探索了基于奇异值分解（SVD）或特征分解（EIG）的非线性缩放，以获得二阶表示的稳定性。

具体来说，Li等人[145]提出将幂指数应用于双线性特征的特征值，以获得更好的识别精度。

G2DeNet [99]通过高斯嵌入和矩阵平方根归一化，进一步结合了互补的一阶和二阶信息。

iSQRT-COV [101]和改进的B-CNN [146]使用牛顿-舒尔茨迭代，仅用矩阵乘法近似矩阵平方根归一化，以减少训练时间。

最近，MOMN [106]被提出在多目标优化框架内同时对平方根、低秩和稀疏性的双线性表示进行归一化。

### *5.2.2 Designing Specifific Loss Functions*

损耗函数在深层网络的建设中起着重要的作用。它们可以直接影响学习到的分类器和特征。因此，设计细粒度定制损失函数是细粒度图像识别的一个重要方向。

与一般图像识别不同的是，在细粒度分类中，属于不同类别的样本在视觉上非常相似，因此可以防止分类器对其输出过于自信（即阻止低熵）。

根据这种直觉，[107]在在细粒度任务上训练网络时，也最大化了输出概率分布的熵。

类似地，Dubey等人[108]使用成对混淆优化程序，通过使不同的类条件概率分布结合在更紧密的地方和混淆深度网络，来解决细粒度识别中的过拟合和与样本特定的伪影。这可以减少预测的过度置信度，从而提高了泛化性能。



人类可以通过比较图像对来有效地识别对比线索，而这种类型的度量/对比学习在细粒度识别中也很常见。

特别地，Sun等人[27]首先学习了多个部分对应的注意区域，然后利用度量学习将相同注意力的同一类别特征拉近，同时远离不同注意力或不同类别特征。此外，他们的方法可以在训练过程中一致地加强不同目标部分之间的相关性。

CIN [109]通过一个对比通道交互模块拉近正对，同时推开负对，该模块也利用了样本之间的通道相关性。

API-Net [111]也建立在一个度量学习框架上，它可以自适应地从一对图像中发现对比线索，并通过基于成对注意力的交互来区分它们。



设计一个单一的损失函数来定位部位级模式和进一步聚合图像级表示。

具体来说，Sun等人[110]开发了一个基于梯度增强的损失函数，以及一个多样化块，以迫使网络快速移动，以区分硬类。具体地说，多样化块抑制了类激活图的判别区域，因此网络被迫寻找替代的信息特征。梯度引导损失关注的重点是每张图像的困难（即混淆）类，并提高它们的梯度。

MC-Loss [112]通过关注不同的部分级区域，鼓励特征通道更具鉴别性。他们提出了一个单一的损失，不需要任何特定的网络细粒度针对对象的部位定位的修改。

上述这些基于损失函数的细粒度识别方法是与主干无关的，它们的性能通常可以通过使用更强大的主干网络架构来提高。

### *5.2.3 Other Methods*

除了建模高阶特征之间的相互作用和设计新的损失函数外，另一组方法还包括构建细粒度定制的辅助任务，以获得统一的和有区别的图像表示。

BGL [50]被提出将丰富的**bipartite-graph labels (BGL)，双偶图标记**合并到CNN训练中，以建模细粒度类之间的重要关系。

DCL [113]进行了“破坏和构建”过程来提高识别难度，引导网络关注细粒度识别的识别部分（即破坏学习），然后对对象部分之间的语义相关性进行建模（即构建学习）。

.与DCL类似，Du等人的[115]使用拼图生成器代理任务来处理细粒度的表示学习，以鼓励网络在不同的粒度级别上学习，并同时将这些级别上的特征融合在一起。

最近，提出了一种更直接的细粒度特征学习方法[147]，其目标是以对抗学习的方式生成具有身份保留的细粒度图像，以直接获得统一的细粒度图像表示。作者表明，这种直接特征学习方法不仅保留了生成图像的身份，而且显著提高了在其他具有挑战性的任务中的视觉识别性能，如细粒度的少镜头学习[148]。

## **5.4 Summary and Discussion**

CUB200-2011 [13]、斯坦福Dogs [42]、斯坦福汽车[43]和FGVC飞机[44]基准测试是细粒度识别中最具影响力的数据集。表2和表3总结了上述三种识别学习范式的细粒度方法的结果，即“端到端定位分类子网络识别”、“端到端特征编码识别”和“外部信息识别”。在图7中可以看到一个按时间顺序排列的概述。主要的观察结果可总结如下：

![image-20220920150642287](D:\文献阅读\image\image-20220920150642287.png)

![image-20220920150653315](D:\文献阅读\image\image-20220920150653315.png)

![image-20220920150759670](D:\文献阅读\image\image-20220920150759670.png)

- 在所审查的方法和上述细粒度识别的挑战之间存在着明确的对应关系。具体来说，捕获细微的视觉差异的挑战可以通过定位-分类方法来克服(cf第5.1节)或通过特定的基于构造的任务[113]，[115]、[147]，以及人工循环方法。通过执行高阶特征交互或利用多模态数据，减轻了表征细粒度定制特征的挑战。最后，FGIA的挑战性可以通过设计特定的损失函数[107]、[108]、[110]来解决一定的问题，以获得更好的准确性。

- 在不同的学习范式中，“定位-分类子网络识别”和“端到端特征编码识别”是最常被研究的两种模式。

- 细粒度物体类别的部分层次推理提高了细粒度识别的准确性，特别是对于非刚性物体，如鸟类。近年来，对区分部分之间的内部语义交互作用/相关性的建模引起了越来越多的关注。[27], [71], [73], [74], [75], [81], [94], [109].

- 非刚性细粒度物体识别（如鸟类或狗）比刚性细粒度物体（如汽车或飞机）更具挑战性，部分原因是由于物体外观的变化。

- 细粒度图像识别性能随着图像分辨率[168]的提高而提高。CUB200-2011中不同图像分辨率的比较结果见表4。

- “定位-分类子网识别”范式在识别和定位能力之间存在权衡，这可能会影响单个集成网络的识别精度。当试图获得更好的识别结果时，这种权衡也反映在实践中，因为训练通常包括交替优化两个网络或单独训练两个网络，然后联合调整。交替或多阶段的策略使集成网络的调谐复杂化。

- 虽然有效，但与定位分类子网络相比，大多数端到端编码网络在非刚性和刚性视觉域上的人解释性较差，准确性也不一致。最近，人们观察到一些高阶池化方法试图通过呈现可视化解释[141]或从优化的角度来看[169]来理解这类方法。
- 当细粒度部分在元类别中不一致时，基于“定位分类子网络的识别”的方法很难应用（例如，自然主义[2]）。在这里，统一的端到端特征编码方法更为合适。

#  6 FINE-GRAINED IMAGE RETRIEVAL

细粒度检索是FGIA的另一个基本方面，近年来获得了更大的吸引力。细粒度检索与细粒度识别的区别在于，除了正确估计子类别外，还需要对所有实例进行排序，以便根据细粒度细节对查询中的图像进行最高排名。

具体地说，在细粒度检索中，我们得到一个包含相同元类别(如鸟或汽车)图像的数据库和一个查询，目标是根据相关细粒度特征返回与查询相关的图像。

一般图像检索侧重于基于内容的相似性（如纹理、颜色和形状）检索接近重复的图像，细粒度检索侧重于检索相同类别类型的图像（例如，相同的从属动物物种或相同的车辆模型）的图像。更具挑战性的是，细粒度类别的对象表现出细微的差异，并且可能在姿态、尺度和方向上有所不同，也可能包含巨大的跨模态差异（例如，在基于草图的检索的情况下）。

细粒度检索技术已广泛应用于商业应用，如电子商务（搜索细粒度产品[172]）、触摸屏设备（通过草图[53]搜索细粒度对象）、预防犯罪（搜索人脸照片[173]）等。根据查询图像的类型，细粒度图像检索中研究最多的领域可以分为两组：细粒度的基于内容的图像检索(FG-CBIR，cf图11)和基于细粒度的基于草图的图像检索(FG-SBIR，cf图12)。细粒度的图像检索也可以扩展为细粒度的跨媒体检索[57]，它可以利用一种媒体类型来检索任何媒体类型，例如使用一个图像来检索相关的文本、视频或音频。

![image-20220920162707287](D:\文献阅读\image\image-20220920162707287.png)

![image-20220920162716029](D:\文献阅读\image\image-20220920162716029.png)

对于性能评估，按照标准约定，FG-CBIR性能通常使用Recall@K [174]来衡量，它是测试集中所有M个查询图像的平均召回分数。对于每个查询，将返回前K个相关图像。如果在前K个返回的图像中至少有一张正面图像，则召回分数将为1，否则为0。

根据公式可知，“召回率@K”的定义如下

![image-20220920162813293](D:\文献阅读\image\image-20220920162813293.png)

对于测量FG-SBIR性能，通常使用精度@acuracy@K，这是其真实匹配照片排在前K位的草图的百分比：

![image-20220920162839804](D:\文献阅读\image\image-20220920162839804.png)

$|I^K_{correct}|$是顶部K的真实匹配照片的数量。

## **6.1 Content-based Fine-Grained Image Retrieval**

SCDA [32]是最早使用深度学习的细粒度图像检索的例子之一。它使用一个预先训练过的CNN，通过定位图像中的主对象来选择有意义的深度描述符，而不使用显式的定位监督.

不出所料，他们表明，通过去除背景特征，在这样种无监督检索设置（即不需要图像标签）中，可以显著提高检索性能。

最近，基于监督度量学习的方法（如[28]，[170]）已被提出，以克服无监督检索的检索精度限制。这些方法仍然包括专门为细粒度对象定制的额外子模块，例如，在[170]中提出的弱监督定位模块，这反过来又受到了[32]的启发。

CRL-WSL [170]采用集中的弱监督定位排序损失方法来训练他们的特征提取器。

DGCRL [28]通过在训练和测试阶段添加归一化尺度层和Global-aware Centralized Ranking Loss(全局感知集中排序损失)来增强类内可分性和类间距离之间的差距,消除了内积和欧氏距离之间的差距。

最近，通过修改传统的交叉熵函数，降低细粒度模型的置信度，提出了分段交叉熵损失[171]，这与遵循细粒度类别[107]、[108]的自然预测置信度分数的基本思想相似。

表5报告了最近细粒度基于内容的图像检索方法的性能。虽然基于监督度量学习的检索方法优于无监督的检索方法，但检索任务的绝对召回分数（即Recall@K）仍有进一步改进的空间。一个很有希望的方向是将先进的技术，如注意机制或高阶特征交互作用，这些技术可以成功地将细粒度识别集成到FG-CBIR中，以获得更好的检索精度。然而，需要新的大规模FG-CBIR数据集来推动未来的进展，这也需要与其他特征或挑战相关联，例如，开放世界的子类别检索(cf。第2节）。

![image-20220920163552578](D:\文献阅读\image\image-20220920163552578.png)
