# Fine-Grained Image Analysis with Deep Learning: A Survey

细粒度图像分析（FGIA）是计算机视觉和模式识别中一个长期存在的基本问题，是一系列现实应用的基础。

FGIA的任务是分析从属类别的视觉对象，如鸟类种类或汽车模型。细粒度图像分析所固有的小的类间变化和大的类内变化使其成为一个具有挑战性的问题。

利用深度学习的进步，近年来，我们见证了深度学习驱动的FGIA的显著进展。

在本文中，我们对这些进展进行了系统的调查，我们试图通过巩固两个基本的细粒度研究领域——细粒度图像识别和细粒度图像检索来重新定义和拓宽FGIA的领域。

此外，我们还回顾了FGIA的其他关键问题，如公开可用的基准数据集和相关的特定领域的应用程序。最后，我们强调了一些需要社区进一步探索的研究方向和开放的问题

# 1 INTRODUCTION

人类的视觉系统天生就具有细粒度的图像推理能力——我们不仅能够区分狗和鸟，而且还能知道西伯利亚哈士奇和阿拉斯加雪橇犬之间的区别（见图1）。细粒度图像分析（FGIA）被引入学术界也是为了同样的目的，即教机器以细粒度的方式“看到”。FGIA方法在工业和研究中都有广泛的应用，例如自动生物多样性监测[1]，[2]，[3]，智能零售[4]，[5]，[6]，和智能交通[7]，[8]，，并在保护[9]和商业[10]等领域产生了积极的影响。 

计算机视觉中的FGIA的目标是检索和识别属于一个超类别的多个下属类别（即元类别或基本级别类别）的图像，如不同种类的动物/植物、不同型号的汽车、不同种类的零售产品等。

因此，关键的挑战在于理解细粒度的视觉差异，这些差异足以区分在整体外观上高度相似，但在细粒度特征上不同的物体。[11]，[12]，[13]自近20年前成立以来已经取得了巨大的进步。

特别是深度学习[14]已经成为一种强大的鉴别特征学习方法，并在FGIA领域取得了显著的突破。支持深度学习的FGIA极大地推进了这些方法在不同应用场景[5]、[7]、[8]、[9]中的实际部署。

近年来，计算机视觉和机器学习研究界都对FGIA产生了极大的兴趣。粗略的统计数据表明，每年在每个高级视觉和机器学习会议上都平均发表了10篇关于基于深度学习的FGIA的>会议论文。还有一些特殊的问题涉及FGIA [15]，[16]，[17]，[18]，[19]。此外，FGIA上一些有影响力的比赛经常在在线平台上举行。代表包括一系列自然主义竞赛（针对大量自然物种）[20]、自然保护渔业监测（鱼类物种分类）[21]、座头鲸鉴定（鲸鱼身份分类）[22]等。每场比赛都吸引了来自世界各地的数百名选手，有些甚至超过2000支队伍。针对FGIA主题的特定教程和研讨会也在顶级国际会议上举行，如[23]，[24]。

尽管有如此突出的兴趣，深度学习的研究仍然支离破碎。

因此，本调查的目的是

(i)提供FGIA近期成果的全面调查，特别是深度学习技术带来的成果，更重要的是

（ii）通过整合FGIA不同方面的研究，提出一个统一的研究战线。我们的方法与现有的调查[25]，[26]有显著的不同，后者只关注细粒度识别/分类的问题，我们认为这只是构成了更大的FGIA研究的一部分。特别是，我们试图通过重新定义和拓宽细粒度图像分析领域，突出细粒度识别之间的协同作用，和并行但互补的任务，这也是FGIA的一个组成部分。

我们的调查采用了一个独特的基于深度学习的视角，以广泛、系统和全面的方式回顾了FGIA的最新进展。

我们的主要贡献总结如下：

- 我们拓宽了FGIA的领域，通过提供一个统一的景观，促进细粒度图像分析中相关问题之间的协同作用。
- 我们提供了基于深度学习的FGIA技术的全面回顾，包括普遍接受的问题定义、基准数据集、不同家族的FGIA方法，以及覆盖特定领域的FGIA应用程序。特别是，我们以分类的方式组织这些方法（参见图2），为读者提供该领域最先进技术的快速快照。

- 我们在几个公开的数据集上整合了现有方法的性能，并提供讨论和见解，为未来的研究提供信息。

- 最后，我们将讨论现有的挑战和开放的问题，并确定新的趋势和未来的方向，为社区解决这些问题提供一个合理的路线图。
- 最后，为了不断跟踪这一快速发展领域的最新发展，我们提供了一个网页，根据我们基于问题的分类对解决FGIA问题的论文进行分类： http://www.weixiushen.com/project/Awesome_FGIA/Awsosk_FGIA.html。

![image-20220919161656930](D:\文献阅读\fine-grained\image\image-20220919161656930.png)

# 2 RECOGNITION VS. RETRIEVAL

以前对FGIA的调查，如[25]，[26]，主要集中于细粒度识别，因此并没有暴露FGIA问题的所有方面。

在本调查中，我们首次涵盖了细粒度图像分析的两个基本领域（即识别和检索），以全面回顾基于深度学习的FGIA技术的最新进展。在图2中，我们提供了一个反映当前FGIA景观的新分类法

**细粒度识别**：我们将不同家族的细粒度识别方法组织成三种范式，即

1)定位分类子网络识别，

2)端到端特征编码识别，

3)外部信息识别。

细粒度识别是FGIA中研究最多的领域，因为识别是大多数视觉系统的基本能力，因此值得长期持续研究。

**细粒度检索**：基于查询图像的类型，我们将细粒度检索方法分为两组，即

1)基于内容的细粒度图像检索和

2)基于草图的细粒度图像检索。

与细粒度识别相比，细粒度检索是近年来FGIA的一个新兴领域，越来越受到学术界和工业界的关注

**识别和检索的差异**:细粒度识别和检索的目的都是识别不同细粒度对象之间的区别性的，但这是不同细粒度对象之间的细微差别。然而，细粒度识别是一项具有固定数量的从属类别的封闭世界任务。相比之下，细粒度检索将问题扩展到具有无限子类别的开放世界设置。此外，细粒度检索还旨在对所有实例进行排序，以便描述感兴趣的概念（例如，相同的子类别标签）的图像根据查询中的细粒度细节排名最高。

**识别和检索协同作用**：在细粒度识别和检索方面的进步有共同之处，并且可以相互受益。细粒度的识别和检索共享了许多常见的技术，如深度度量学习方法[27]、[28]、多模态匹配方法[29]、[30]，以及选择有用的深度描述符[31]、[32]的基本思想等。第7节详细讨论。此外，在现实应用中，细粒度识别和检索也相互补充，例如，检索技术能够通过利用从细粒度识别模型[5]，[33]中学习到的表示来支持新的子类别识别。

# 3 BACKGROUND: PROBLEM AND CHALLENGES

细粒度图像分析（FGIA）侧重于处理属于同一元类别的多个从属类别的对象（如不同种类的鸟类或不同的汽车模型），通常涉及两个中心任务：细粒度图像识别和细粒度图像检索。如图3所示，细粒度分析是在基本级类别分析（即通用图像分析）和实例级分析（如个体识别）之间的连续体。

![image-20220919170253807](D:\文献阅读\image\image-20220919170253807.png)

具体来说，FGIA与通用图像分析的区别在于，在通用图像分析中，目标对象属于粗粒度元类别（即基本级别类别），因此在视觉上完全不同（例如，确定图像是否包含鸟、水果还是狗）。**然而，在FGIA中，由于对象通常来自同一元类别的子类别，因此问题的细粒度性质导致它们在视觉上是相似的**。作为细粒度识别的一个例子，在图1中，任务是对不同品种的狗进行分类。为了准确的图像识别，有必要捕捉细微的视觉差异（例如，有区别特征，如耳朵、鼻子或尾巴）。对于其他FGIA任务（例如，检索），也需要描述如此的特征。此外，如前所述，由于问题的细粒度性质具有挑战性，由高度相似的子类别引起的类间变化，以及姿态、尺度和旋转的大变化（见图4）。因此，它与一般的图像分析（即，小的类内变化和大的类间变化）相反，并使FGIA成为一个独特的和具有挑战性的问题。

虽然实例级分析通常针对对象的特定实例，而不仅仅是对象类别或对象子类别，但如果我们向下移动粒度谱，在极端情况下，个体识别(例如，人脸识别)可以被视为细粒度识别的特殊实例，其中粒度位于个体身份级别。

例如，人/车辆再识别[7]，[34]可以被认为是一个细粒度的任务，其目的是确定是否为同一特定的人/车辆拍摄了两张图像。在实际应用中，这些工作利用与FGIA相关的方法解决了相应的领域特定问题，如捕获对象（[8]、人脸、人、车辆）的识别部分，发现从粗到细的结构信息[37]，开发基于属性的模型[38]、[39]等。对这些实例级问题的研究也非常活跃。然而，由于这些问题不在经典FGIA的范围内（见图3），有关更多信息，我们请读者调查这些特定主题的论文，如[7]，[34]，[40]。下面，我们首先阐述我们对经典FGIA的定义。

**公式**：在一般图像识别中，我们给出一个训练数据集$D=\{(x^{(n)}，y^{(n)})|i = 1，...，N\}$，包含多个图像和相关的类标签（即x和y），其中$y∈[1，...，C]$。每个实例（x、y）根据pr (x、y）的分布，都属于图像空间和标签空间（即x和y）的联合空间

![image-20220919171742869](D:\文献阅读\image\image-20220919171742869.png)

特别地，标签空间Y是与C类别对应的所有C子空间的并集空间，即$Y = Y_1∪Y_2∪···∪Y_c∪···∪Y_C$。

然后，我们就可以训练一个预测/识别深度网络f（x；θ）由θ参数化，通过最小化预期风险进行通用图像识别

![image-20220919172132011](D:\文献阅读\image\image-20220919172132011.png)

其中，L（·，·）是一个损失函数，它度量真实标签与f（·；θ）预测的标签之间的匹配。而如前所述，细粒度识别的目的是从某个元类别中准确地分类不同从属类别的实例，即：

![image-20220919172222021](D:\文献阅读\image\image-20220919172222021.png)

其中，y'表示细粒度的标签，Yc表示类c的标签空间为元类别。因此，细粒度识别的优化目标是作为

![image-20220919172323083](D:\文献阅读\image\image-20220919172323083.png)

与细粒度识别相比，除了细粒度检索正确外，还必须对所有实例进行排序，以便在检索任务查询中根据细粒度细节对属于同一子类别的图像排名最高。

给定一个输入查询$x^q$，细粒度检索系统的目标是根据它们与查询的细粒度相关性，对检索集$Ω=\{x^{(i)}\}^M_{i=1}$（其标签y'∈Yc）中的所有实例进行排序。让$S_Ω = \{s^{(i)}\}^M_{i=1}$表示$x^q$和每个$x^(i)$之间的相似性，通过应用于相应的细粒度表示的预定义度量来测量，即$h（x^q；δ）$和$h(x^{(i)};δ)$。这里，δ表示检索模型h的参数。对于那些标签与$x^q$的细粒度类别一致的实例，我们将它们形成一个正集$P_q$，并得到相应的$S_P$。然后，可以通过最大化基于排名的分数来对检索模型h（·；δ）进行训练

![image-20220919173123790](D:\文献阅读\image\image-20220919173123790.png)

所有的查询图像，其中$R(i，S_P)$和$R(i，S_Ω)$分别表示实例i在$P_q$和Ω中的的排名。

# 4 BENCHMARK DATASETS

近年来，视觉社区发布了许多细粒度的基准数据集，涵盖了不同的领域，例如，鸟类[1]、[13]、[41],狗[27],[42],[43]汽车,飞机[44],
花[45]，蔬菜[46]，水果[46]，食物[47]，时尚[6]，[33]，[38]，零售产品[5]，[48]等。此外，值得注意的是，即使是最流行的大规模图像分类数据集，即ImageNet [49]，也包含了覆盖许多狗和鸟子类别的细粒度类。

在图5中可以找到来自其中一些细粒度基准数据集的代表性图像。在表1中，我们总结了最常用的图像数据集，并指出了它们的元类别、图像的数量、类别的数量、它们的主要任务，以及额外的可用监督，例如，边界框、部分注释、层次标签、属性标签和文本描述(cf。图6）。

![image-20220919185134271](D:\文献阅读\image\image-20220919185134271.png)

![image-20220919185150251](D:\文献阅读\image\image-20220919185150251.png)

这些数据集是该领域取得重大进展的最重要因素之一，不仅是衡量和比较竞争方法性能的共同点，而且也推动该领域向日益复杂、实际和具有挑战性的问题发展。

细粒度鸟类分类数据集CUB-200- 2011 [13]是最流行的细粒度数据集之一。大多数的FGIA方法都选择它来与最先进的方法进行比较。此外，在CUB200-2011上对高级任务的持续贡献，例如，收集细粒度图像的文本描述用于多模态分析，cf[58]，[59]和第5.3.2节。

近年来，人们提出了更具挑战性和实用的细粒度数据集，例如，iNat2017包含不同种类的植物和动物[2]，以及用于零售产品[5]的RPC。这些数据集的新特性包括：它们是大规模的，具有层次结构，表现出一个域间隙，并形成一个长尾分布。这些挑战说明了FGIA在现实世界中的实际要求，并激发了新的有趣的研究挑战。第8节）。

除此之外，我们还构建了一系列基于细粒度草图的图像检索数据集，如QMUL-Shoe [52]、QMULChair [52]、QMUL-potys[54]、SBIR2014 [51]、SBIR2017 [55]、素描[53]、QMUL-Shoe-V2 [56]，以进一步推进细粒度检索的发展，cf。第6.2节。此外，我们还构建了一些新的数据集和基准测试，如FG-Xmedia [57]，将细粒度图像检索扩展到细粒度跨媒体检索

# 5 FINE-GRAINED IMAGE RECOGNITION

细粒度图像识别是近十年来FGIA最活跃的研究领域。细粒度识别的目的是区分属于同一基本类别的许多视觉上相似的从属类别，如动物物种[2]、汽车[43]、水果[46]、飞机模型[44]等的精细区分。它经常被应用于现实世界的任务中，如生态系统保护（识别生物物种）[9]、智能零售系统[5]、[10]等。由于区分区域定位和细粒度特征学习的挑战，识别细粒度类别是困难的。研究人员已经试图从不同的角度来应对这些挑战。在本节中，我们将回顾自深度学习出现以来主要的细粒度识别方法

一般来说，现有的细粒度识别方法可以组织成以下三种主要范式：

- 定位分类子网络识别；
- 端到端特征编码识别；
- 利用外部信息识别。

其中，前两种范例只利用与细粒度图像相关联的监督来限制自身，如图像标签、边界框、部件注释等。为了进一步解决模糊的细粒度问题，有大量的工作使用额外的信息，如图像在何时拍摄[60]，[61]，web图像[62]，[63]，或文本描述[58]，[59]。为了直观地展示这些具有代表性的基于深度学习的细粒度识别方法，我们在图7中通过将它们组织成上述三个范式来进行时间顺序概述。

![image-20220919191223222](D:\文献阅读\image\image-20220919191223222.png)

对于性能评估，当测试集是平衡的时（即，每个类都有一个类似的数字测试示例），细粒度识别中最常用的度量是数据集所有从属类别的分类精度。将其定义为

![image-20220919191442917](D:\文献阅读\image\image-20220919191442917.png)

$|I_{total}|$表示测试集中所有子类别的图像数量，$|I_{correct}|$表示模型正确分类的图像数量。

## 5.1通过定位-分类子网进行的识别

研究人员试图创建模型来捕获细粒度对象的区别语义部分，然后构建与这些部分相对应的中层表示，用于最终的分类，cf图8. 更具体地说，设计了定位关键部分，然后得到相应的部分级（局部）特征向量。这通常与对象级(全局)图像特性结合使用，以表示细粒度的对象。

![image-20220919191706771](D:\文献阅读\image\image-20220919191706771.png)

接下来是一个执行识别的分类子网络。这两个协作子网的框架形成了第一个范式，即使用定位-分类子网的细粒度识别。这些模型的动机是首先找到相应的部分，然后比较它们的外观。具体地说，我们希望捕获在细粒度类别中共享的语义部分（例如，头部和躯干），并发现这些部分表示之间的细微差异。

该范例中现有的方法可以分为四种主要类型： 1)使用检测或分割技术，2)使用深度过滤器，3)利用注意机制，以及4)其他方法。

### 5.1.1采用检测或分割技术

采用检测或分割技术[116]、[117]、[118]可以直接定位与细粒度物体部分对应的关键图像区域，如鸟头、鸟尾、汽车灯、狗耳、狗的躯干等。多亏了定位的信息，，即部分级边界框或分割掩码，该模型可以获得更有鉴别性的中层（部分级）表示w.r.t.这些部分。从而可以进一步提高分类子网络的学习能力，从而显著提高最终的识别精度.

在这个范例中的早期工作使用了额外的密集部分注释(又名关键点标注，cf图6左边)，以定位对象的语义关键部分。

例如，Branson等人[64]提出使用检测到的部分关键点组来计算多个扭曲的图像区域，并通过姿态归一化进一步得到相应的部分级特征。

在同一时期，Zhang等人[65]首先基于地面真实部分标注生成部分级边界框，然后训练R-CNN [118]模型进行部分检测。

Di等人[67]进一步提出了一种 Valve Linkage Function，该函数不仅连接了所有子网，而且根据*part alignment*结果细化了定位。

为了集成语义部分检测和抽象，SPDA-CNN [69]设计了一种自上而下的方法，通过继承先验的几何约束来生成*part-level*建议，然后使用更快的R-CNN [116]返回部分定位预测。

其他的方法则利用了分割信息。PS-CNN [68]和Mask-CNN [31]采用分割模型得到部位/对象掩码，以帮助部位/对象定位。与检测技术相比，分割可以得到更精确的部分定位[31]，因为分割侧重于更精细的像素级目标，而不仅仅是粗糙的边界框。

____

然而，使用传统的检测器或分割模型需要密集的部分注释来进行训练，这是劳动密集型的，并将限制现实世界的细粒度应用程序的可伸缩性和实用性。因此，我们希望仅使用图像级标签[70]、[72]、[73]、[74]、[75]就可以准确地定位细粒度的部位。这些方法被称为“弱监督”，因为它们只使用图像级标签。值得注意的是，自2016年以来，在这种弱监督设置中开发细粒度方法有一个明显的趋势，而不是强监督设置（即使用部分注释和边界框），cf表2。

在基于弱监督定位的分类设置中，识别方法总是依赖于无监督方法来获得与对象部分相对应的语义群。

具体来说，Zhang等人的[70]采用了空间金字塔策略[119]从对象提案生成部分建议。然后，通过使用聚类方法，他们生成部分建议原型聚类，并进一步选择有用的聚类来获得有区别的部分级特征。

基于共分割[120]的方法也常用于这种弱监督的情况下。一种方法是在不受监督的情况下使用共分割来获得对象掩模，然后执行启发式策略，如部分约束[72]或部分对齐[66]，以定位细粒度的部分。



___

值得注意的是，以往的大部分工作都忽略了区分部分级特征之间的内部语义相关性。具体地说，上述方法独立地挑选出区分区域并直接利用其特征，而忽略了对象的特征相互语义相关，区域组更有区分性的事实。

因此，最近，一些方法试图联合学习部分级特征之间的相互依赖关系，以获得更通用、更强大的细粒度图像表示。

通过执行不同的特征融合策略(如LSTMs[71]，[73]，graphs[74]，或知识蒸馏[75])，这些联合部分特征学习方法获得了显著更高的识别率
优于以前的独立部分特征学习方法。

### 5.1.2利用深度过滤器
